A Project plan  
On 
NeuroLearn: An AI -Powered Adaptive Learning Platform for 
Neurodiverse Students  
Submitted to  
Amity University Uttar Pradesh  
 
In partial fulfillment  of the requirements for the award of the degree of  
Bachelor of Technology  
in  
Computer Science and Engineering  
by  
Aakash Khandelwal  
(A23052222 92) 
7CSE4  
 
Under the guidance of 
Dr. Rajni Sehgal  
 
Department of Computer Science & Engineering  
Amity School of Engineering and Technology  
Amity University Uttar Pradesh  
2025  
II 
 DECLARATION  
 
I Aakash Khandelwal  (A23052222 92) hereby declare that the report titled “NeuroLearn: 
An AI -Powered Adaptive Learning Platform for Neurodiverse Students”  which is 
submitted by me to the Department of Computer Science, Amity School of Engineering 
Technology, Amity University Uttar Pradesh, Noida, in partial fulfillment of the 
requirement for the award of the degree of Bachelor of Technology in Computer Scien ce 
and Engineering, has not been previously formed the basis for the award of any degree, 
diploma or other similar title or recognition . The Author attests that permission has been 
obtained for the use of any copy righted material appearing in the Dissertation / Project 
report other than brief excerpts requiring only proper acknowledgment in scholarly writing 
and all such use is acknowled ged. 
 
 
 
 
Date:  
Aakash Khandelwal  
A23052222 92 
2022 -2026  
 
 
 
 
 
 
 
 
 III 
 CERTIFICATE OF ACKNOWLEDGEMENT  
On the basis of declaration submitted by Aakash Khandelwal  (A23052222 92), student(s) 
of B. Tech (CSE), I hereby certify that the project titled “ NeuroLearn: An AI -Powered 
Adaptive Learning Platform for Neurodiverse Students ” which is submitted to Department 
of Computer Science, Amity School of Engineering Technology, Amity University Uttar 
Pradesh, Noida, in partial fulfillment of the of the requirement for the award of the degree 
of Bachelor of Technology in Computer Scienc e & Engineering, is an original contribution 
with existing knowledge and faithful record of work carried  out by him/them under my 
guidance and supervision.  
To the best of my knowledge this work has not been submitted in part or full for any Degree 
or Diploma to this University or elsewhere . 
 
 
 
 
 
 
Dr. Rajni Sehgal  
Amity School of Engineering & Technology  
Amity University Noida, Uttar Pradesh (AUUP)  
 
 
 
 
 
 
 
 
 IV 
 ABSTRACT  
NeuroLearn is a project idea that focuses on building an AI -based learning platform for 
students who learn in different ways. It’s mainly designed for learners with Autism 
Spectrum Disorder (ASD), ADHD, Dyslexia, and Dyspraxia. Most e -learning platforms 
today try to personalize the content, but they usually don’t think much about how students 
actually interact with the platform. Many students struggle not because the content is hard, 
but because the design and experience are not made for them. NeuroLearn ai ms to change 
that by mixing smart AI features with a design that is easy to use and accessible for 
everyone.  
The system uses a hybrid recommendation method that mixes collaborative filtering, 
content -based filtering, and some simple rule -based logic. It also follows UDL (Universal 
Design for Learning) principles and WCAG 2.1 accessibility standards. On top of tha t, it 
includes affective computing —basically, the platform adjusts based on how the student is 
interacting in real time, but it does this while keeping their data private and secure. The 
technical setup is based on the MERN stack plus machine learning, whi ch allows the 
system to adapt things like how content is shown, the difficulty level, timing, and how 
information is presented to each learner.  
For this project, the team followed a design science approach. Over ten weeks, they went 
through research papers and articles from IEEE, Springer, ACM, and similar sources. They 
studied how current adaptive learning systems work, looked into neurodiverse e ducation, 
personalization through AI, and the rules around accessibility and ethics. By analyzing 
different platforms, they found many areas that could be improved and used those insights 
to build their own theoretical model.  
The main output of this project is a clear framework that links AI personalization with 
accessibility right from the start. It also suggests better ways to measure performance, not 
just through accuracy but by checking accessibility, cognitive load, and fa irness. Another 
important part is an ethical framework that protects user privacy, makes algorithms more 
transparent, and works to reduce bias. The team also created a technical plan for how this 
could be built —covering the MERN architecture, recommendatio n system, data handling, 
and interface design.  V 
 From what the research shows, hybrid recommendation systems work better than single 
methods, especially in classrooms where data is often limited. Building accessibility and 
UDL features from the beginning gives students more flexibility and makes the inte rface 
simpler to use. There’s also the option to include emotion -aware features, which can help 
keep students engaged. These features are designed carefully with privacy in mind —
everything runs locally, and students have full control over what they want to  share. This 
not only builds trust but also creates a smoother learning experience.  
Results indicate that the proposed integrated approach addresses previously unrecognized 
gaps at the intersection of adaptive learning algorithms, cognitive accessibility standards, 
and ethical AI deployment in education. The theoretical validation through  scenario -based 
analysis and comparative evaluation against existing systems establishes a strong 
foundation for prototype development and empirical validation in the upcoming major 
project phase. The comprehensive documentation, including weekly progress reports, 
design diagrams, algorithm specifications, and evaluation frameworks, provides actionable 
guidance for implementation while contributing to the broader academic discourse on 
inclusive educational technology design.  
The project delivers a research -grounded foundation positioned to advance both technical 
understanding of adaptive systems and practical approaches to neurodiverse educational 
inclusion. Future work includes prototype development using the specified MERN+M L 
technology stack, small -scale user testing with appropriate ethical oversight and 
neurodiverse participant engagement, quantitative algorithm validation with realistic 
educational datasets, accessibility compliance auditing through third -party evaluation , and 
longitudinal assessment of impacts on learning outcomes, engagement, and learner self -
efficacy.  
Keywords:  Adaptive learning systems, Neurodiversity, Cognitive accessibility, WCAG 
2.1, Universal Design for Learning, Hybrid recommendation algorithms, MERN stack 
architecture, Machine learning personalization, Affective computing, Educational 
technology, Privacy -by-design, Ethical AI, Inclusive education, Assistive technology, 
Special education technology  VI 
 LIST OF TABLES  
Table 1: Project Goals and Success Criteria  
Table 2: Functional Requirements Summary  
Table 3: Non -Functional Requirements Summary  
Table 4: Project Timeline and Milestones  
Table 5: Roles and Responsibilities Matrix  
Table 6: Risk Assessment Matrix  
Table 7: Comparison of Existing Adaptive Learning Platforms  
Table 8: Evaluation Metrics for Hybrid Recommendation Systems  
Table 9: Technology Stack Components and Justification  
Table 10: Performance and Scalability Projection  
LIST OF FIGURES  
Figure 1: Neurodiverse Learning Challenges Framework  
Figure 2: Evolution of Adaptive Learning Systems  
Figure 3: Conceptual MERN+ML System Architecture  
Figure 4: Hybrid Recommendation Engine Workflow  
Figure 5: Cognitive Load Adaptation Decision Model  
Figure 6: Accessibility Controls and Interface Customization Mockup  
Figure 7: Privacy -First Affective Computing Data Flow  
Figure 8: Accessibility Compliance Assessment Results  
Figure 9: Ethical AI Governance Framework for Education  
 
 
 
 
 VII 
 Table of Contents  
1. INTRODUCTION  ................................ ................................ ................................ ............  1 
1.1 Purpose of Plan ................................ ................................ ................................ ...........  1 
1.2 Background Information/Available Alternatives ................................ ..........................  3 
1.2.1 Traditional Learning Management Systems  ................................ ..........................  3 
1.2.2 Adaptive Learning  Platforms  ................................ ................................ ................  4 
1.2.3 Accessibility -Focused Educational Technologies  ................................ ..................  6 
1.2.4 Emerging Research Prototypes ................................ ................................ ..............  7 
1.3 Project Goals and Objectives ................................ ................................ .......................  8 
2. SCOPE  ................................ ................................ ................................ ...........................  14 
2.1 Scope Definition  ................................ ................................ ................................ ....... 14 
2.2 Projected  Budget  ................................ ................................ ................................ ....... 18 
3. CONSTRAINTS  ................................ ................................ ................................ ............  22 
3.1 Project Constraints  ................................ ................................ ................................ .... 22 
4. REQUIREMENT ANALYSIS  ................................ ................................ .......................  28 
4.1 Functional Requirements  ................................ ................................ ........................  28 
4.2 Non -Functional Requirements  ................................ ................................ ...................  32 
5. PROJECT MANAGEMENT APPROACH ................................ ................................ ..... 34 
5.1 Process Framework  ................................ ................................ ................................ ... 34 
5.2 Project Timeline ................................ ................................ ................................ ........  36 
5.3 Roles and Responsibilities ................................ ................................ .........................  37 
5.4 Communication Plan  ................................ ................................ ................................ . 37 
6. RISK ASSESSMENT ................................ ................................ ................................ ..... 38 
6.1 Risk Identification ................................ ................................ ................................ ..... 38 
6.2 Risk Analysis  ................................ ................................ ................................ ............  39 
6.3 Risk Evaluation and Prioritization  ................................ ................................ .............  39 
6.4 Risk Treatment Strategies  ................................ ................................ .........................  40 
6.5 Monitoring and Review ................................ ................................ .............................  41 
7. LITERATURE REVIEW  ................................ ................................ ...............................  42 
7.1 Neurodiversity in Education  ................................ ................................ ......................  42 
7.2 Adaptive Learning and Artificial Intelligence  ................................ ............................  43 
7.3 Recommender Systems in Education  ................................ ................................ .........  44 
7.4 Accessibility Standards and Universal Design for Learning  ................................ ....... 45 
7.5 Affective Computing in Education  ................................ ................................ ............  45 
7.6 Research Gaps and NeuroLearn’s Contributions ................................ ........................  46 VIII  
 8. METHODOLOGY  ................................ ................................ ................................ .........  48 
8.1 Design Science Research Framework  ................................ ................................ ........  48 
8.2 Interdisciplinary Integration  ................................ ................................ ......................  49 
8.3 Research Rigor and Relevance  ................................ ................................ ..................  50 
8.4 Limitations ................................ ................................ ................................ ................  50 
8.5 Summary  ................................ ................................ ................................ ..................  50 
9. SYSTEM DESIGN AND ARCHITECTURE  ................................ ................................ . 51 
9.1 Conceptual Architecture ................................ ................................ ............................  51 
9.2 Component Interactions  ................................ ................................ ............................  53 
9.3 Security and Privacy Considerations  ................................ ................................ .........  56 
9.4 Technology Stack Justification  ................................ ................................ ..................  56 
10. IMPLEMENTATION DETAILS ................................ ................................ ..................  58 
10.1 Planned Technology Stack  ................................ ................................ ......................  58 
10.2 Development Environment  ................................ ................................ ......................  59 
10.3 Testing and Quality Assurance  ................................ ................................ ................  60 
10.4 Deployment and Maintenance  ................................ ................................ .................  60 
11. RESULTS AND ANALYSIS  ................................ ................................ .......................  62 
11.1 Hybrid Recommendation  Performance  ................................ ................................ .... 62 
11.2 Accessibility Compliance Assessment  ................................ ................................ ..... 64 
11.3 Privacy and Trust Impact  ................................ ................................ ........................  65 
11.4 Fairness and Bias Evaluation  ................................ ................................ ...................  66 
11.5 Summary  ................................ ................................ ................................ ................  66 
12. DISCUSSION  ................................ ................................ ................................ ..............  67 
13. CONCLUSION AND FUTURE WORK  ................................ ................................ ...... 69 
14. INDIVIDUAL CONTRIBUTION  ................................ ................................ ................  70 
15. REFERENCES  ................................ ................................ ................................ .............  73 
 
 
 
 
 
 1 
 1. INTRODUCTION  
1.1 Purpose of Plan  
The purpose of this research project is to develop a comprehensive theoretical framework 
for NeuroLearn , an AI -powered adaptive learning platform specifically designed to 
address the educational needs and challenges faced by neurodiverse students. This work is 
conducted as a Minor Project (ETMN100) under the B.Tech Computer Science and 
Engineering program a t Amity School of Engineering & Technology, representing a 
research -intensive exploration at the intersection of artificial intelligence, educational 
technology, cognitive psychology, and inclusive design principles.  
Neurodiversity is about changing the way we look at different ways people think and learn. 
It recognizes conditions like Autism Spectrum Disorder (ASD), ADHD, Dyslexia, and 
Dyspraxia not as problems to be fixed, but as natural differences in how human brai ns 
work. These differences actually make our world more diverse and creative. More and 
more schools around the world are starting to understand that students who learn differently 
deserve the same access to learning as everyone else.  
The problem is that most technology solutions still fall short. Accessibility is often added 
at the end of the design process, almost like an extra feature, instead of being built into the 
system from the start. This is why many existing platforms don’t fu lly support the needs 
of neurodiverse learners.  
 
Learning Management Systems (LMS) and new adaptive learning platforms are examples 
of current educational technologies that mostly focus on changing the complexity and order 
of content based on how well students do. This method only looks at one part of 
customisation, and it doesn't take into account the whole range of cognitive accessibility 
needs that are very important for neurodiverse learners. Students with ADHD may find it 
hard to use interfaces that have too many visual distractions and stimulation.  Students with 
autism may need interface patterns that are very predictable and constant, as well as clear, 
direct instructions. People with dyslexia benefit from certain font choices, customizable 
text spacing, and content that is presented in more than o ne way. Dyspraxia impacts how 2 
 well you can control your body and coordinate your movements, thus you need to be very 
attentive when designing interactions and input methods.  
The NeuroLearn research project fills this gap by suggesting a unified framework that 
brings together advanced AI -driven personalization with broad cognitive accessibility 
principles. Instead of treating algorithmic personalization and accessibility as two  separate 
issues, with data scientists in charge of the first and separate teams in charge of the second, 
our a pproach recognizes that for adaptive learning to really work for neurodiverse 
populations, both aspects need to be integrated from the very beginning of system design.  
This small part of the project is all about building a strong theoretical base through a lot of 
reading, creating a conceptual framework, designing the system architecture, and setting 
the evaluation criteria. The study investigates the creation of hybrid recommendation 
algorithms that include Collaborative Filtering, Content -Based Filtering , and rule -based 
limitations, ensuring compliance with cognitive accessibility standards while preserving 
the efficacy of personalization. We examine the operationalization of Universal Design for 
Learning (UDL) principles and Web Content Accessibility Gui delines (WCAG 2.1) as 
dynamic system behaviors rather than static design decisions. Our project explores how we can 
use emotional computing to make learning more engaging and less frustrating for students, all while 
carefully protecting their privacy and p ersonal autonomy.  
This is a collaborative effort by three Computer Science Engineering students: Aakash 
Khandelwal, Naman Singhal, and Yash Goyal, under the guidance of our supervisor, Ms. 
Rajni Sehgal, an expert in AI and machine learning. From late July to September 2025,  our 
team conducted a thorough review of academic literature, analyzed existing learning 
platforms, and developed the conceptual designs and practical roadmaps for our system.  
Beyond its technical goals, this work is deeply rooted in social justice and educational 
equality. We challenge the common belief that you have to choose between performance 
and inclusive design. Our research shows that advanced AI systems can be built wit h 
accessibility as a core feature, not an afterthought. We hope our findings will encourage 
developers everywhere to adopt an "accessibility -first" mindset.  
Our research contributes to several fields. For computer science, we are improving how 
recommendation algorithms handle sparse educational data while meeting accessibility 3 
 standards. In human -computer interaction, we are turning abstract accessibility rules into 
concrete, adaptable system behaviors. For education, we are providing a framework to 
support neurodiverse students on their own terms, rather than forcing them to fi t into a rigid 
system. And for ethics and policy, we are creating guidelines for the responsible use of AI 
with vulnerable student groups.  
This report summarizes the process and findings of our project's initial phase. It establishes 
our theoretical foundation, evaluates our approach against existing research, and lays out a 
detailed plan for building and testing a prototype in the next phase . This work is a 
significant step toward creating fully inclusive educational technology that works for all 
learners by respecting their cognitive diversity, privacy, and personal agency.  
1.2 Background Information/Available Alternatives  
Educational technology has been completely transformed over the last 20 years. We've 
gone from tools that were basically just digital textbooks to much smarter systems that can 
personalize the learning experience for each student. Looking closely at how we  got here, 
and at the tools available today, provides the essential backstory for our NeuroLearn 
project. It shines a light on where current tech is still falling short, which is exactly what 
our framework is designed to fix.  
1.2.1 Traditional Learning Management Systems  
Think about the big learning platforms many of us are familiar with, like Moodle, 
Blackboard, Canvas, and Google Classroom. At heart, they're really just digital filing 
cabinets. They give teachers a central place to upload course materials, hand out quizz es, 
run discussions, and track basic things like logins or if an assignment was turned in.  
While most of them have some basic accessibility features, like being compatible with 
screen readers, they don't really adapt to the student. They aren't designed to personalize 
the learning experience with algorithms or address the needs of students with different 
cognitive styles. Because of this, it's no surprise that research shows these one -size-fits-all 
platforms can be a real struggle for neurodiverse students.  
Students with ADHD who have trouble with selective attention and executive function can 
get overwhelmed by dashboards that are too busy and have too many sources of 
information. Autistic learners who do better with routine and predictability have trouble 4 
 when navigation patterns are inconsistent and interface changes are unanticipated. Students 
with dyslexia have trouble with text -heavy interfaces that don't let them change the font. 
Multimedia content with a set pace and strict deadlines makes it harder f or students who 
have different processing speeds or attention patterns to learn.  
Even with these problems, traditional LMS platforms are still the most common type of 
technology used in schools throughout the world. This is because they have a lot of 
features, schools are slow to adopt new technologies, they work well with current 
administrative systems, and IT departments are used to them. Any alternative solution, 
including NeuroLearn, must recognize this reality and explore integration pathways with 
existing systems instead of presuming complete replacement.  
1.2.2 Adaptive Learning  Platforms  
Second -generation adaptive learning systems are a big step forward in technology 
compared to previous LMS platforms since they use AI and machine learning algorithms 
to make learning more personal. Knewton Alta, DreamBox Learning, Smart Sparrow, 
ALEKS (Ass essment and Learning in Knowledge Spaces), and Carnegie Learning's 
MATHia are some of the most important commercial platforms in this group.  
These systems usually include advanced algorithms for knowledge tracing (figuring out 
what students know and don't  know), item response theory (figuring out how hard a 
question is and how well a student can answer it), and recommendation engines (figuring 
out what the next learning activity should be). The personalization works mostly along one 
axis: the difficulty an d order of the content. The algorithms change the difficulty level of 
the next issues based on how well the students did on the exam. They also find gaps in 
students' prior knowledge and suggest additional material when necessary.  
Studies on the efficacy of adaptive learning yield inconclusive outcomes. Meta -analyses 
show that learning results are better with this method than with traditional instruction, with 
effect sizes usually between 0.2 and 0.4 standard deviations. Nonetheless, these 
enhancements are  not uniformly allocated among student demographics. There aren't many 
studies that look at how neurodiverse learners are affected differently, but the ones that do 
show that traditional adaptive systems may not meet their needs and may even make things 
worse in some circumstances.  5 
  
For starters, they're often obsessed with just getting the right answer, while completely 
ignoring how a student is feeling or if the material is truly accessible to them. The 
algorithms they use are frequently a black box, so students are left guessing wh y a certain 
topic was suggested to them. Most of these systems are also designed for a very narrow 
type of "neurotypical" user, and they don't give learners much control —you have to adapt 
to the platform, not the other way around. On top of all that, ther e are major privacy 
concerns about how much data they collect and what they do with it. Their entire definition 
of success is often just about speed and accuracy, overlooking crucial things like a student's 
engagement, persistence, or growing confidence.  
 
From a neurodiversity standpoint, this is a huge problem. These systems are basically built 
on a flawed, one -size-fits-all assumption about how people learn, rewarding one specific 
cognitive style at the expense of all others. For example, their focus on m oving through 
content quickly can end up punishing students who need more time to process information 
and understand it on a deeper level. The emphasis on correctness and efficiency can make 
people less likely to try new things and work through problems. T he algorithmic evaluation 
of suitable difficulty levels may not consider the inconsistent skill profiles seen in 
neurodiverse populations, where pupils may thrive in certain domains while encountering 
challenges in others.  
 6 
  
Figure 1: Neurodiverse Learning Challenges Framework  
 
[A conceptual graphic showing how variances in sensory sensitivities, cognitive load, 
temporal processing, and preferred ways of interacting can all come together to make 
learning harder for neurodiverse kids.]  
1.2.3 Accessibility -Focused Educational Technologies  
A third group of important technologies is made up of customized tools and platforms that 
are made just for students with disabilities. Examples include Read&Write literacy support 
software, Ghotit spelling and grammar checker for dyslexia, Sonocent audio note -taker, 
Kurzweil educational systems, and various text -to-speech and speech -to-text applications.  
The issue with these specialized tools is that they exist in their own bubbles. Even though 
they offer great support, they're standalone programs, forcing students into a clunky routine 
of switching between a bunch of different systems that just don't talk  to each other. For 
7 
 example, they need to use their school's LMS to get to course materials, specialized reading 
software to read documents with a lot of text, separate note -taking apps to take notes during 
lectures, and other organizational tools to keep track of tasks and d ue dates. This 
fragmentation adds to the cognitive strain of those who may already have trouble with 
executive function and managing tasks.  
Also, specialist accessibility tools typically have negative connotations.  Students may be 
reluctant to use visibly different technologies that mark them as "different" from peers. The 
requirement to seek and configure specialized tools places additional burden on students 
who already face educational challenges. Integration of accessibility features into 
mainstream educational platforms, as proposed in the NeuroLearn framework, has the 
potential to reduce stigma, simplify technology interactions, and benef it broader student 
populations beyond those with identified disabilities.  
1.2.4 Emerging Research Prototypes  
Academic research has produced various prototype systems exploring different aspects of 
adaptive, accessible, and affective educational technology. However, most remain at proof -
of-concept stages without widespread deployment or sustained development. Comm on 
patterns in research prototypes include narrowly focused implementations addressing 
specific dimensions (e.g., affective tutoring systems, accessible interface research, or 
recommendation algorithms) without comprehensive integration; limited scalabilit y due to 
resource -intensive approaches unsuitable for institutional deployment; insufficient 
attention to privacy, security, and ethical governance; lack of sustainable development and 
maintenance beyond initial research project completion; and minimal lon gitudinal 
evaluation of actual impacts on learning outcomes or educational equity.  
The NeuroLearn research project learns from both the successes and limitations of these 
diverse existing approaches. By proposing an integrated framework that combines 
algorithmic sophistication with comprehensive accessibility, privacy -preserving design 
with sophisticated personalization, and evidence -based principles with practical 
implementation feasibility, this work aims to advance both the theoretical understanding 
and practical deployment of truly inclusive adaptive educational technology.  8 
 1.3 Project Goals and Objectives  
So, what's our game plan for the NeuroLearn project? We've built it around five main goals 
that all connect and build on each other. You can think of them as our complete roadmap 
for creating better and more inclusive learning technology. For each of those  goals, we've 
laid out specific targets, clear benchmarks for what success looks like, and the core ideas 
driving our work. Together, all these details provide the blueprint for the system we plan 
to build.  
Table 1: Project Goals and Success Criteria  
Goal  Objective  Success Criteria  
Adaptive 
Intelligence  Develop hybrid recommendation 
framework combining 
collaborative filtering, content -
based filtering, and rule -based 
constraints  Demonstrated theoretical 
RMSE < 0.8; ability to handle 
cold-start with CBF 
initialization  
Cognitive 
Inclusivity  Operationalize UDL principles 
and WCAG 2.1 guidelines as 
dynamic interface behaviors  Comprehensive mapping of 5 
key WCAG criteria to adaptive 
UI controls; cognitive load 
threshold framework  
Emotional 
Sensitivity  Design privacy -first on -device 
emotion detection with transparent 
consent and non -paternalistic 
adaptations  Affective module architecture 
specified; consent model with 
granular opt -in/out; adaptation 
triggers defined  
Data -Driven 
Validation  Establish multi -dimensional 
evaluation framework balancing 
accuracy, accessibility, 
engagement, fairness  Evaluation methodology 
including RMSE, coverage, 
WCAG compliance metrics, 
bias detection protocols  
Sustainable 
Implementation  Propose MERN + ML architecture 
with pragmatic deployment and 
maintenance guidelines  Detailed system architecture; 
technology stack justification; 
integration pathways with 
LMS standards  9 
  
Goal 1: Adaptive Intelligence Through Hybrid Recommendation  
Our first major goal is technical: we need to figure out how to give students good, 
personalized recommendations. This is uniquely challenging in education because we often 
have limited data on student activity, deal with many different types of content, m ust follow 
established teaching principles, and need to make sure the recommendations are easy for 
students to understand.  
This is why traditional recommendation methods, when used by themselves, really struggle 
in a school setting. Common approaches like collaborative filtering (which suggests 
content based on what similar users liked) and content -based filtering (which match es 
content to a user's profile) both run into major problems here.  
Specific Objectives:  
• To achieve this, our plan is to build a hybrid algorithm that combines the best parts 
of different recommendation methods.  
• This will also help us solve the classic "cold -start" problem —when a new student 
joins and we have no data on them —by using content -based suggestions to give them 
a smart starting point.  
• A crucial part of the design is balancing the system's ability to enforce strict 
educational rules, like prerequisites, with the flexibility to adapt to each student's 
personal accessibility settings.  
• Develop explanation mechanisms supporting learner understanding and control . 
• Make sure that recommendations are varied and new so that algorithms don't create 
echo chambers.  
 
Theoretical  Contributions : 
This study enhances comprehension of the constraints and optimization of machine 
learning algorithms to achieve educational objectives beyond mere engagement 
maximization. We show a novel way to develop AI that is inclusive by making 10 
 accessibility needs computational limitations instead of filters that are applied after the 
fact. The hybrid architecture serves as a model for further educational technology 
applications that necessitate customization within intricate domain -specific limi tations.  
Goal 2: Cognitive Inclusivity Through Operationalized Accessibility  
Next, we need to translate all the great ideas about accessibility into something the software 
can actually do. It's about putting theory into practice. We have fantastic guidelines like 
the Universal Design for Learning principles and WCAG 2.1 success cri teria, but they're 
more like a destination on a map than a set of GPS directions. They tell you what  an 
inclusive system should achieve, but not how to build it, especially when AI is involved. 
We're aiming to fill that gap.  
Specific Objectives:  
• Map WCAG 2.1 success criteria to specific interface adaptation mechanisms  
• Transform UDL principles from static design patterns to dynamic system capabilities  
• Develop cognitive load assessment approaches suitable for real -time adaptation 
decisions  
• Create maintenance plans that help users predict what will happen next, so they can 
adjust to changes without feeling confused or lost.  
Design customization options for accessibility that give users enough control over 
the system while still keeping it simple and easy to use.  
Theoretical Contributions:  
This study connects research on making human -computer interaction more accessible with 
research on machine learning systems by showing how abstract ideas might help 
algorithms make decisions. The cognitive load evaluation framework combines 
psychological t heory with measurable interface measurements. The research demonstrates 
that accessibility and personalization are complementary design objectives when 
considered comprehensively from the outset of system design.  
Goal 3: Emotional Sensitivity with Privacy -Conscious Affective Computing  11 
 The third goal talks about the chance and the problem of adding emotional awareness to 
educational technology. Research indicates that affect recognition might enhance 
engagement, diminish frustration, and facilitate self -regulation; yet, it also presents 
considerable privacy issues and the potential for paternalistic intervention that 
compromises learner autonomy.  
 
Specific Objectives:  
• Create emotion recognition architectures for devices that don't send sensitive data  
Create detailed, easy -to-use consent systems that give users complete control over 
affective features  
• Create adaptation strategies that help learners instead of controlling them  
• Set up strong fallback systems that keep all features working when affective 
features are turned off  
• Use clear logging and explanations of affective inferences and adaptations  
Theoretical Contributions: This research enhances privacy -preserving methodologies in 
affective computing by introducing architectural improvements that prioritize edge 
processing and data minimization. The ethical framework for educational affective AI 
tackles specific issues that come up when working with vulnerable groups and power 
relations in institutions. The study shows that advanced personalization and strong privacy 
protection can work together with careful technical and governance design.  
Goal 4:  Validation Based on Data Through a Thorough Review  
The fourth goal sets up strict ways to evaluate inclusive adaptive educational systems. 
Conventional machine learning assessment prioritizes predictive accuracy and 
computational efficiency, whereas educational technology evaluation frequently 
concentrates  solely on the impact of learning outcomes. Neither sufficiently addresses the 
comprehensive array of considerations pertinent to systems catering to neurodiverse 
populations.  
 12 
  
Specific Objectives:  
• Create a multi -dimensional evaluation framework that includes measurements of 
accuracy, accessibility, engagement, fairness, and learning outcomes . 
• Set up techniques for finding bias that show systematic disadvantages for certain 
neurotype groups . 
• Create long -term evaluation methods that look at how long -lasting effects on self -
efficacy, educational persistence, and long -term results are.  
• Make evaluation methods that include all stakeholders and take into account the 
views of neurodiverse learners.  
• Set minimum acceptable performance levels for all evaluation areas . 
 
Theoretical Contributions:  
 
This study broadens the approaches for evaluating instructional technology by illustrating 
that effectiveness cannot be measured using unidimensional criteria. The bias detection 
methods derived from fairness in machine learning research tackle specific is sues in 
educational settings, where variations in performance may indicate authentic diversity 
rather than algorithmic bias. The multi -stakeholder evaluation framework serves as a 
model for a broader approach to technology assessment that includes everyon e.  
Goal 5: Use of Pragmatic Architecture for Long -Term Implementation  
The fifth goal is to make sure that ideas don’t just look good in theory but can actually 
work in real schools. A lot of research prototypes show that a concept is possible, but they 
often ignore things like how the system can grow, how much work it will t ake to maintain, 
whether it fits with the school’s current setup, or if it can keep working well over time.  
Specific Objectives:  
• Set up a MERN+ML system that is strong enough to handle the work but simple 
enough to build and manage.  13 
 • Use open -source tools that the school or institution can easily support.  
Make sure the new system can connect and work well with the school’s current 
LMS and admin systems.  
• Set up security and privacy rules that match the needs of the institution .  
• Write documentation and training materials that will help with long -term use and 
upkeep . 
Theoretical Contributions:  
 
Our main goal here is to bridge the gap between academic research and what actually works 
in the real world. We're focusing on the practical challenges that most papers tend to ignore. 
That’s why we’re designing the system to be modular —so it can be adopte d piece by piece 
and grow over time. The idea is to build something sustainable, ensuring our research turns 
into a tool that lasts.  
Everything is guided by five connected goals aimed at advancing both the theory and the 
real-world application of inclusive learning tech. This first phase was all about laying the 
groundwork: developing the theory, seeing how it stacks up against other re search, and 
mapping out what it will take to make it a reality. The next step is to build a prototype, test 
it in actual schools, and refine it based on real feedback.  
 
 
 
 
 
 
 14 
 2. SCOPE  
2.1 Scope Definition  
Since this is just a one -semester project, we needed to be realistic about our scope and 
focus on what we could actually achieve. This phase is all about laying the groundwork for 
the bigger task of building and testing the system later on. Here, we'll spe ll out exactly 
what this project covers and what we're saving for future work.  
In-Scope Activities and Deliverables  
Comprehensive Literature Review:  
To start this project, we had to do a ton of background research, pulling together ideas 
from all over the map. We dug into the nuts and bolts of adaptive learning systems, 
machine learning for personalization, and the principles of Universal Design for 
Learning. A big piece of our focus was on accessibility, so we studied neurodiversity in 
education and the specifics of the Web Content Accessibility Guidelines. We also 
explored crucial topics like privacy -preserving AI, the  ethics of using these tools with 
vulnerable students, and even how technology can recognize and respond to a student's 
emotions.  
The literature review includes peer -reviewed academic articles from well -known sources 
like the IEEE Xplore Digital Library, the ACM Digital Library, Springer journal 
databases, magazines for educational technology experts, and journals for cognitive 
psych ology and neuroscience. The review identifies current state of research, established 
best practices, identified gaps and oppor tunities, comparative analyses of existing 
systems and approaches, and theoretical frameworks grounding the proposed NeuroLearn 
design.  
Theoretical Framework Development:  
The project develops comprehensive theoretical models integrating multiple research 
domains including hybrid recommendation system architecture combining collaborative 
filtering, content -based filtering, and rule -based decision -making; cognitive accessibil ity 
framework operationalizing UDL and WCAG principles as system behaviors; privacy -
by-design approach for sensitive learner data handling; evaluation methodology 15 
 balancing traditional ML metrics with accessibility and fairness considerations; and 
ethical governance model for responsible AI deployment in educational contexts.  
These frameworks are validated through literature analysis, expert consultation with 
faculty advisors, scenario -based theoretical evaluation, and comparative analysis against 
existing approaches.  
Conceptual System Design:  
The minor project includes detailed conceptual design of the NeuroLearn system 
architecture covering overall system architecture using MERN stack with ML 
microservices; component design specifying roles and interactions of UI, API, database, 
and ML modules ; data model design for user profiles, accessibility preferences, content 
metadata, and interaction logging; algorithm specifications for hybrid recommendation, 
cognitive load assessment, and adaptive interface decisions; and priv acy and security 
architecture implementing data protection and access control.  
Design artifacts include system architecture diagrams mapping component relationships 
and data flows, database schema specifications with privacy controls, algorithm 
pseudocode for key personalization mechanisms, interface mockups demonstrating 
accessibili ty features, and security protocols for data protection and user privacy.  
Evaluation Framework Specification:  
The project establishes comprehensive evaluation criteria and methodologies including 
performance metrics for recommendation accuracy and system responsiveness, 
accessibility compliance assessment against WCAG 2.1 and UDL standards, cognitive 
load measurem ent approaches, engagement and satisfaction metrics, fairness and bias 
detection protocols, and longitudinal impact assessment approaches.  
The evaluation framework provides guidance for systematic assessment of system 
effectiveness across multiple dimensions and identifies specific testing and validation 
activities for the major project phase.  
Implementation Roadmap:  
The minor project delivers a detailed plan for prototype development and validation 16 
 including technology stack specifications with justification, development environment 
setup procedures, testing strategies spanning unit, integration, and accessibility testing, 
deployment considerations for institutional contexts, timeline with milestones  for major 
project activities, and risk mitigation strategies for identified challenges.  
Comprehensive Documentation:  
The project produces thorough documentation including this formal project report 
meeting ETMN100 guidelines, weekly progress reports (WPRs) documenting research 
activities, design diagrams and technical specifications, literature review summaries and 
bibli ographic references, and presentation materials for project defense.  
Out-of-Scope Activities  
Actual System Implementation:  
The minor project does not include coding and development of functional system 
components. No database setup or data collection is performed. No frontend or backend 
implementation is completed. No machine learning model training occurs. No 
deployment to we b servers or cloud platforms is undertaken. This substantial 
implementation work is explicitly reserved for the major project phase when additional 
time, resources, and technical infrastructure will be available.  
User Research and Testing:  
The minor project does not conduct primary research with human subjects. No 
recruitment of neurodiverse learners for studies occurs. No usability testing sessions are 
held. No empirical validation of proposed approaches is performed. No institutional 
revie w board (IRB) approval is sought at this stage. Empirical validation with actual 
users is a critical component of the major project phase and will be conducted with 
appropriate ethical oversight and participant protections.  
Quantitative Algorithm Validation:  
The minor project does not perform computational experiments with real or simulated 
datasets. No implementation of recommendation algorithms for performance 
benchmarking occurs. No statistical analysis of algorithm accuracy or efficiency is 
conducted. Algo rithm validation remains theoretical, based on literature evidence and 17 
 logical analysis. Quantitative validation will occur in the major project phase once 
algorithms are implemented.  
Integration with Existing Systems:  
The minor project does not include actual integration with institutional LMS or student 
information systems. No API development for external system connections occurs. No 
data migration or transformation from existing systems is performed. Integration 
planning is conceptual, identifying requirements and approaches for future 
implementation.  
Commercial Viability Analysis:  
The minor project does not conduct market research or business planning. No cost -
benefit analysis for institutional adoption is performed. No competitive analysis of 
commercial educational technology products occurs. No intellectual property or 
commerciali zation strategies are developed. The focus remains on academic research 
contributions and educational equity goals rather than commercial potential.  
Scalability and Performance Optimization:  
The small project doesn't do any comprehensive performance testing or optimization 
work. There is no assessment of load or planning for capacity. There is no optimization 
of database queries or installation of a caching method. Architectural design choices  
address performance issues theoretically, and specific optimization is put off until the 
main project implementation phases.  
Multilingual and Cross -Cultural Adaptation:  
Multilingual assistance and cross -cultural adaption of the NeuroLearn system are 
acknowledged as vital for comprehensive inclusion; nonetheless, they exceed the 
parameters of this first research phase. The initiative concentrates on English -language 
enviro nments and predominantly utilizes research from Western educational systems, 
recognizing this constraint and highlighting internationalization as a significant area for 
future development.  
This carefully defined  scope makes sure that the little project makes important theoretical 
contributions and lays a strong foundation for future work, all while being doable in the 18 
 ten-week time span and with the limited resources of a student research project. The 
thorough documentation and careful preparation make it easy to move from the planning 
and implementation phases to the validation phases of the significant project.  
2.2 Projected  Budget  
The NeuroLearn minor project is a cost -effective research effort that makes the most of 
free academic resources, open -source software, and institutional infrastructure. This 
method makes sure that it is possible to do within the usual limits of student pro jects, while 
also laying the groundwork for future implementation that may require more resources and 
money.  
Hardware Requirements and Costs  
Student Laptops/Personal Computers:  
All three members of the team use their own laptops to do research, write reports, design, 
and work together. Minimum hardware specifications include 8GB RAM for smooth 
operation of development tools and documentation software, Intel Core i5 or equivalent 
processor for adequate processing power, 256GB SSD storage for operating system, 
applications, and project fil es, stable internet connectivity for accessing online research 
databases and collaboration tools, and webcam and microphone for virtual meetings a nd 
guide consultations.  
These devices represent zero additional cost for the project as they are already owned by 
students for academic purposes. No specialized hardware such as GPU acceleration for 
machine learning model training is required during the minor project phase as 
implementation and computational experiments are deferred to the major project.  
Software and Tools - No Cost  
Development Environment:  
Visual Studio Code (VS Code) serves as the integrated development environment, 
providing free, open -source code editing with extensive plugin ecosystem. Node.js and 
npm enable JavaScript/TypeScript development environment for future MERN stack 
implementati on. MongoDB Community Edition provides database management system 19 
 for future data persistence needs. Python and Anaconda deliver machine learning 
development environment with Jupyter Notebook for algorithm prototyping and 
documentation.  
Research and Reference Management:  
Zotero provides free, open -source reference management with IEEE citation style support 
for organizing the extensive literature collected throughout the project. Google Scholar 
offers free academic search engine for discovering relevant research publicatio ns. Notion 
or similar free note -taking applications enable organized documentation of research 
findings, meeting notes, and collaborative work.  
Communication and Collaboration:  
WhatsApp, Microsoft Teams, and Google Meet provide free communication platforms 
for team coordination, guide meetings, and progress discussions. Google Drive and 
OneDrive offer free cloud storage with sufficient capacity for project documentation and 
colla borative editing of reports and presentations.  
Design and Diagramming:  
Draw.io  (diagrams.net ) provides free, web -based diagramming tool for creating system 
architecture diagrams, flowcharts, and conceptual models. Figma Community Edition 
offers free UI/UX design tool for interface mockups demonstrating accessibility features. 
Canva Free delivers presentation design tool for creating professional project defense 
slides.  
Academic Database Access - Institutional Subscription  
IEEE Xplore Digital Library:  
Comprehensive access to IEEE journals, conference proceedings, and standards 
documents relevant to computer science, educational technology, and human -computer 
interaction research. Access provided through Amity University institutional subscription 
at no direct cost to students.  
Springer and ACM Digital Libraries:  
Extensive academic publication databases covering machine learning, artificial 20 
 intelligence, accessibility research, and educational technology domains. Institutional 
subscriptions enable unlimited access to journal articles, conference papers, and technical 
reports essential for thorough literature review.  
Other Academic Resources:  
Amity University library provides access to numerous additional academic databases, 
electronic books, and research resources supporting comprehensive literature review 
across multiple domains relevant to NeuroLearn research.  
Documentation and Report Preparation - No Cost  
Microsoft Office Suite:  
Students have access to Microsoft Word, PowerPoint, and Excel through institutional 
licenses or free student subscriptions for creating formal project reports, presentations, 
and data tables meeting ETMN100 formatting requirements.  
LaTeX (Optional):  
Free, open -source document preparation system providing professional typesetting for 
technical documentation, mathematical formulas, and academic publications should 
students choose to use it for portions of documentation.  
Printing and Binding Costs - Minimal  
Final Report Printing:  
ETMN100 guidelines require submission of two printed, spiral -bound copies of the final 
project report. Estimated printing and binding costs are approximately Rs. 500 -800 per 
copy (Rs. 1,000 -1,600 total) based on expected report length of 40 -50 pages with c olor 
diagrams and figures. This represents the primary direct cost incurred by students for 
project completion.  
Presentation Materials:  
Minimal costs may be incurred for any physical presentation materials required for 
project defense, estimated at Rs. 200 -300 if needed.  
Total Projected Budget Summary  21 
 Hardware:  Rs. 0 (using existing personal computers)  
Software and Development Tools:  Rs. 0 (free and open -source)  
Academic Research Database Access:  Rs. 0 (institutional subscriptions)  
Communication and Collaboration Tools:  Rs. 0 (free platforms)  
Documentation and Office Software:  Rs. 0 (institutional licenses)  
Printing and Binding:  Rs. 1,000 -1,600 (required submission copies)  
Presentation Materials:  Rs. 200 -300 (if needed)  
Contingency (10%):  Rs. 200  
Total Estimated Project Cost:  Rs. 1,500 -2,100  
This minimal budget demonstrates the cost -effectiveness and feasibility of conducting 
high-quality academic research using available institutional resources, open -source 
software ecosystems, and collaborative tools. The low financial barrier enables studen ts to 
focus intellectual energy on research quality rather than resource acquisition.  
Future Implementation Budget Considerations  
While beyond the scope of the minor project, the team acknowledges that full system 
implementation in the major project phase may involve additional costs including cloud 
hosting services for application deployment (AWS, Google Cloud, or Azure student cred its 
may offset), API services for specialized functionality if needed (many offer free tier usage 
sufficient for academic projects), potential user testing participant compensation (if ethical 
review requires), and extended development tools or services th at exceed free tier 
limitations.  
However, the careful selection of open -source technologies and cloud platforms with 
generous student/academic free tiers in the NeuroLearn architecture design aims to 
minimize or eliminate these costs even during implementation phases. The project shows 
that you can make big changes in educational technology without spending a lot of money. 
This makes it possible for both student researchers and schools that don't have a lot of 
money to develop technology that works for everyone.  22 
 3. CONSTRAINTS  
3.1 Project Constraints  
The NeuroLearn minor project works under a number of restrictions that affect research 
methods, limit the project's scope, and affect design choices. Clearly defining and writing 
down these limits makes guarantee that project planning is practical, the rig ht research 
method is chosen, and the limits that affect how results are understood and how future work 
is planned are communicated clearly.  
Temporal Constraints  
Ten-Week Project Duration:  
The minor project has a set ten -week time frame (July 21, 2025, to September 28, 2025) 
that is based on the academic semester structure and the requirements for the ETMN100 
course. Because of this short time constraint, research goals must be clear, work m ust be 
divided up among team members in an efficient way, and the scope must be carefully 
defined to make sure that deliverables can be finished on time and with the right level of 
quality.  
The 10 weeks are not enough time for a  full system implementation, a lot of user testing, 
or a long -term effect assessment. These big tasks should be put off until the main project 
phase, which will last for two academic semesters and have much more time available. 
The minor project timetable does allow for significant literature assessment, construction 
of a theoretical framework, design of a conceptual system, and complete documentation 
as key deliverables.  
Competing Academic Responsibilities:  
At the same time, team members are taking classes for other seventh -semester subjects, 
doing lab work, completing assignments, and taking tests, all of which require their time 
and attention. The project has to be balanced with these other schoolwork, whic h means 
that you may only spend a certain amount of hours each week on NeuroLearn research.  
Weekly Progress Report submission requirements necessitate consistent participation and 
documentation throughout the project l ength. This helps keep progress stable despite 23 
 competing demands, but it also means that documentation activities must be done on a 
frequent basis.  
Resource and Infrastructure Constraints  
No Research Budget:  
The project runs without any extra money, save for the small expenditures of printing the 
final report. This means that you can't buy commercial software licenses, specialized 
gear, cloud computing resources beyond the free tiers, access to premium researc h tools 
or datasets, or pay participants for user research.  
The limitation pushes people to choose open -source technologies, uses institutional 
subscriptions to give researchers access to academic databases, and changes the way 
researc h is done to focus on developing theories instead of proving them with money.  
Limited Computing Infrastructure:  
Instead of high -performance computing resources, team members use their own laptops 
with low -end specs (8GB RAM, consumer -grade processors). This makes it impossible to 
work with huge datasets or train machine learning models that need a lot of processing 
power. It also makes it harder to do computational experiments or prototype algorithms.  
The limitation is suitable considering the project's primary focus on theoretical study 
rather than practical implementation; nonethe less, it does affect choices regarding 
algorithm complexity and computational methodologies in conceptual designs.  
Institutional Infrastructure Limitations:  
Data privacy rules, a lack of authorized access for student research projects, no 
established partnership mechanisms for such access, and ethical review requirements for 
research involving human subjects data mean that the project can't use institutional 
learning management systems, student information systems, or educational datasets for 
research purposes.  
These limitations are entirely appropriate for protecting student privacy and complying 
with ethical research standards but do constrain the research to theoretical modeling rather 
than data -driven empirical validation.  24 
 Data and Access Constraints  
No Primary Data Collection:  
The minor project does not involve collecting data from human subjects through surveys, 
interviews, user testing sessions, or system interaction logs. This reflects both ethical 
constraints requiring institutional review board (IRB) approval for human subj ects 
research and practical constraints of limited time insufficient for lengthy ethical review 
processes.  
The absence of primary data collection limits empirical validation of proposed frameworks 
and shifts research emphasis to theoretical development grounded in existing literature. 
User research with neurodiverse learners is planned for the major project pha se with 
appropriate ethical oversight.  
Reliance on Published Literature:  
Research findings and validations rely entirely on existing published academic literature, 
publicly available information about commercial educational technology platforms, and 
theoretical analysis rather than original empirical research. This constrains t he novelty of 
certain research contributions and limits the ability to validate specific claims about 
neurodiverse learner needs beyond  existing literature documents.  
However, comprehensive literature synthesis across multiple domains rarely examined 
together (adaptive learning algorithms, cognitive accessibility, affective computing, 
educational ethics) does enable novel theoretical contributions even without primary d ata 
collection.  
No Access to Proprietary System Details:  
Commercial adaptive learning platforms typically do not publish detailed information 
about their algorithms, data structures, or privacy practices beyond general marketing 
descriptions. This limits the depth of comparative analysis between NeuroLearn and 
existing alternatives and requires reliance on academic publications studying these 
systems rather than direct examination of system implementations.  
 25 
 Technical and Methodological Constraints  
No System Implementation:  
The most significant constraint is the exclusion of actual system implementation, coding, 
and deployment from the minor project scope. This means proposed approaches cannot 
be validated through functional prototypes, algorithm performance cannot be measure d 
through actual implementations, interface designs cannot be tested with real users, and 
system scalability cannot be assessed through actual deployment.  
This constraint is deliberate and appropriate given the ten -week timeline but does limit the 
research contribution to theoretical and conceptual domains rather than demonstrating 
practical feasibility through working systems. Implementation is the central focus of the 
planned major project phase.  
Limited Algorithm Validation:  
Without implementation and access to appropriate educational datasets, algorithm 
specifications cannot be validated through quantitative performance testing. Claims about 
hybrid recommendation effectiveness, cognitive load assessment accuracy, or adaptive 
decision quality rely on theoretical analysis and analogies to published research rather 
than empirical measurement.  
Future work must include rigorous quantitative validation of algorithmic approaches once 
implementation enables such testing.  
Simplified Problem Scope:  
The NeuroLearn framework focuses on specific neurotypes (ASD, ADHD, Dyslexia, 
Dyspraxia) and particular educational contexts (higher education, individual learners, 
web-based interfaces) rather than attempting comprehensive coverage of all neurodiverse 
conditions, all educational levels, all learning contexts, or all technology platforms.  
This scoping constraint ensures depth over breadth and enables focused research within 
available time and resources. However, it limits direct generalizability of findings to 
excluded contexts and populations, which would require additional research to add ress. 
 26 
 Ethical and Regulatory Constraints  
Human Subjects Protection:  
All research must comply with ethical standards for human subjects research, including 
obtaining informed consent, protecting participant privacy, avoiding harm to vulnerable 
populations, maintaining data security, and submitting protocols for institutiona l review 
when appropriate.  
These rules are good for protecting research participants, but they do limit the methods 
that student researchers can use and make studies that involve people take longer. The 
small project's purely theoretical approach avoids these problems and sets up et hical 
guidelines for future empirical inquiry.  
Privacy and Data Protection:  
The project must follow all relevant privacy laws and best practices, such as principles of 
data minimization, requirements for consent and user control, security measures for 
sensitive information, and openness about how data is used and shared.  
The NeuroLearn framework embraces privacy -by-design principles from the first 
conceptual stages, perceiving privacy constraints not as limits but as design possibilities 
that promote user trust and system appropriateness for educationa l contexts.  
Institutional Policies:  
Research must comply with Amity University norms regarding student research projects, 
academic integrity standards, intellectual property regulations, restrictions on external 
collaboration, and guidelines for resource utilization.  
These limitations are constantly managed by supervisory guidance, NTCC oversight, 
proper attribution and citation protocols, and documented adherence to project 
specifications . 
Knowledge and Expertise Constraints  
Student Researcher Limitations:  
As undergraduate students, team members possess developing rather than expert -level 
knowledge in pertinent fields, including advanced machine learning algorithms, cognitive 27 
 psychology and neuroscience, accessibility standards and assistive technologies, 
educational research methodologies, and user experience research involving vulnerable 
populations.  
The team mitigates these constraints by doing comprehensive literature reviews, 
engaging with faculty advisors, and maintaining a suitable level of humility regarding 
their research contributions. The learning process itself is an essential result of the p roject 
since students become more knowledgeable in these areas.  
Single Advisor Availability:  
Professor Rajni Sehgal, who is an expert in artificial intelligence and machine learning, is 
the project's main faculty advisor. While they are very knowledgeable in technical fields, 
a full interdisciplinary coverage would ideally include more advisors wh o are experts in 
special education, accessibility research, educational psychology, and ethics.  
The constraint is mitigated by a comprehensive literature analysis that incorporates expert 
information from academic publications ; nonetheless, direct interaction with a variety of 
specialists would enhance specific facets of the research.  
Institutional Context Limitations:  
The research takes place in a technical university's computer science engineering 
department, which means that the resources, evaluation criteria, and research 
expectations are all focused on technical contributions. This setting is really good for the 
algorithmic and system design parts of NeuroLearn, but it doesn't help as much with 
educational research or disability studies points of view that would make a fully 
multidisciplinary approach better.  
Recognizing and unders tanding these different limitations makes it possible to accurately 
interpret research contributions, realistically evaluate what the small project can 
accomplish with the resources it has, clearly communicate the limitations that affect 
results, and effec tively plan for future work that can deal with current limitations. As we 
move into the major project phase, many of the constraints we had in this first stage will 
be lifted. This will let us shift from theoretical research to practical application, allow ing 
us to build a working prototype and begin testing it in the real world.  
 28 
 4. REQUIREMENT ANALYSIS  
This phase is all about figuring out exactly what the system needs to do. We look at what 
users are asking for, consider the rules and realities of the educational world, and turn that 
into a specific set of technical requirements. The whole point is to en sure that the 
NeuroLearn platform is built on a strong base of proven educational philosophy, 
accessibility principles, and solid adaptive learning research.  
4.1 Functional Requirements  
1. User  Authentication and Authorization  
The starting point for a platform like this is a secure login system. We'll use a 
modern method called JSON Web Tokens (JWTs) to verify who a user is —a 
student, a teacher, or an admin —so they don't have to keep putting in their 
credentials. On top of that,  we'll manage permissions with Role -Based Access 
Control (RBAC). This is a simple but crucial principle: you only get access to 
what you need for your role. This is what prevents a student from, for example, 
editing a course or seeing a teacher's private d ata. 
2. User Profile Management  
Personalized learning is all about building an accurate profile for each student. 
This profile can't just be their name and class schedule; it must also include their 
learning goals and accessibility choices. Research shows that personalization 
works best when it also considers cognitive traits like working memory and 
processing speed.  
With that in mind, NeuroLearn specifically keeps track of:  
• Accessibility Settings: Things like preferred font size, contrast, and page 
layouts that are designed to support cognitive accessibility.  
• Learning Preferences: The student's goals and the types of content they 
engage with most, which is guided by the UDL principle of offering 
multiple ways to learn.  
3. Hybrid Recommendation Engine  
An educational recommender system has to do more than just make accurate 29 
 predictions; its suggestions must be educationally valuable. We use a mix of 
methods to achieve this. Collaborative Filtering suggests content based on peer 
activity, but it struggles in new courses that lack data. To solve this, we also use 
Content -Based Filtering, which analyzes an item's details (like its learning 
objective or difficulty) to match it with a student's profile. Finally, to ensure 
educational integrity, we apply a set of rules to make sure that:  
• Knowledge graphs have prerequisite structures.  
• Accessibility filters that get rid of content that is too hard for users to 
understand (for example, when there is too much information, the 
interface gets simpler).  
• We are building the system with clear privacy rules that are centered on 
user choice and consent for how their data will be used.  Explanations 
follow best practices for explainable AI, which means that they show 
users why a recommendation was made, which helps develop trust.  
4. Adaptive Interface Controls  
Cognitive load theory distinguishes between intrinsic, external, and relevant 
burden. NeuroLearn changes unnecessary load on the fly by:  
• Making layouts simpler when the predicted cognitive load goes above the 
limits set by UI complexity measures (element count, navigation depth).  
• Giving timing controls (pause, prolong timeouts) that are in line with WCAG 
2.2.1 Timing Adjustable.  
• Giving each user profile the ability to change the way their senses work (less 
motion, high contrast, dyslexia -friendly typefaces).  
5. Affective Computing Module (Optional)  
Affective computing looks at how feelings can change how we learn. NeuroLearn 
uses behavioral signal analysis (such keyboard timing and mouse movement 
entropy) to figure out if someone is frustrated or not engaged without violating 
their privacy. On -device  inference follows privacy -by-design, and opt -in consent 
systems follow ethical rules for groups that are at risk. Adaptations, such as 30 
 suggestions for breaks, respect the learner's freedom and don't interfere in a 
paternalistic way.  
6. Progress Tracking and Analytics  
Self-regulated learning theory underscores the importance of goal setting, 
monitoring, and reflection. Dashboards visualize progress toward goals, time -on-
task, and achievement patterns. Instructors view aggregated data with anonymized 
accessibility usage metrics to inform inclusive teaching strategies.  
7. Content Management  
Robust content management enables metadata -driven personalization. Content 
items include:  
• Pedagogical metadata: learning objectives, Bloom’s taxonomy level.  
• Accessibility annotations: WCAG compliance flags, alternative formats.  
• Prerequisite links: knowledge graph relationships enabling sequencing 
logic.  
8. Help and Support  
Contextual help systems guided by user interaction patterns (e.g., repeated errors) 
improve usability and reduce frustration. Accessible FAQ and live support 
channels provide human assistance when automated help is insufficient.  
 31 
  
Figure 5: Cognitive Load Adaptation Decision Model  
[Flow diagram illustrating how UI complexity metrics and interaction patterns feed into 
an interpretable ensemble model that triggers interface mode shifts (simple, standard, 
advanced).]  
Table 2: Functional Requirements Summary  
Category  Requirement  
Authentication  OAuth 2.0/JWT login; role -based access control  
Profile Management  Storage of accessibility preferences, learning goals, content 
modality choices  
Recommendation 
Engine  Hybrid CF/CBF/rules engine; explainable AI; fairness 
constraints  
Interface Adaptation  Dynamic UI complexity modes; timing controls; sensory 
customization  
32 
 Affective Computing  On-device emotion inference; opt -in consent; adaptation 
suggestions  
Progress Analytics  Real-time dashboards; instructor -view analytics; 
downloadable reports  
Content Management  Metadata tagging (learning objectives, WCAG flags, 
prerequisites); version control  
Help & Support  Contextual help prompts; accessible FAQ; support contact  
 
4.2 Non -Functional Requirements  
1. Performance and Scalability  
Real-time adaptivity is critical; studies indicate adaptation delays over 1 s degrade 
engagement. NeuroLearn targets <500 ms recommendation generation and <200 
ms UI adaptation using in -memory caches and asynchronous microservices.  
2. Security and Privacy  
Data minimization and encryption at rest/in transit follow GDPR -like principles. 
Audit logs and fine -grained consent records support accountability.  
3. Accessibility Compliance  
Full WCAG 2.1 AA conformance ensures perceivable, operable, understandable, 
and robust content. Cognitive accessibility extensions from W3C’s Cognitive 
Accessibility Task Force guide interface behaviors.  
4. Reliability and Availability  
A distributed microservices architecture with health checks and auto -scaling 
ensures ≥99.5% uptime. Graceful feature degradation preserves core functionality 
under duress.  
5. Usability  
Conformance with Nielsen’s usability heuristics and ISO 9241 -210 user -centered 
design guarantees intuitive navigation, clear feedback, and error prevention.  33 
 6. Maintainability  
SOLID software engineering principles and modular design enable independent 
updates to recommendation, UI, and analytics components.  
7. Interoperability  
RESTful APIs with OpenAPI specifications and optional GraphQL support 
facilitate integration with institutional LMS via LTI standards.  
8. Legal and Ethical Compliance  
Ethical AI frameworks ensure transparency, fairness, and human oversight. Data 
protection policies align with institutional and international regulations.  
Table 3: Non -Functional Requirements Summary  
Attribute  Specification  
Performance  Recommendation ≤ 500 ms; UI adaptation ≤ 200 ms  
Scalability  Support ≥ 1,000 concurrent users; auto -scaling microservices  
Security  AES-256 at rest; TLS 1.3 in transit; RBAC; audit logs  
Privacy  GDPR -style consent; data minimization; on -device processing for 
emotion data  
Accessibility  WCAG 2.1 AA compliance; ARIA landmarks; keyboard 
navigation; screen -reader support  
Reliability  99.5% uptime SLA; graceful degradation of non -critical features  
Usability  Nielsen’s heuristics; consistent navigation; clear feedback; error 
prevention  
Maintainability  Modular microservices; SOLID principles; documented APIs  
Interoperability  REST/GraphQL APIs; LTI standard compatibility  
Ethical 
Compliance  Transparency; fairness auditing; human oversight; redress 
mechanisms  
 
 
 34 
 5. PROJECT MANAGEMENT APPROACH  
Effective management of a complex, interdisciplinary research project such as NeuroLearn 
requires combining structured project management principles with agile, iterative practices 
tailored to academic research. This section details the project’s process f ramework, 
timeline, roles, and communication mechanisms to ensure timely delivery of high -quality 
theoretical artifacts.  
5.1 Process Framework  
NeuroLearn follows a hybrid model integrating the five PMBOK process groups with 
Agile sprint -based iterations:  
1. Initiating  
o Define project charter documenting objectives, scope, deliverables, and 
success criteria.  
o Identify stakeholders (faculty supervisor, departmental advisors, potential 
future users).  
o Establish risk register capturing initial project risks and mitigation 
strategies.  
2. Planning  
o Develop Work Breakdown Structure (WBS) decomposing tasks into 
literature review, requirement analysis, design, methodology, and 
documentation.  
o Create integrated schedule mapping dependencies (e.g., finalize 
requirements before architecture design).  
o Allocate resources, leveraging institutional database subscriptions and 
open -source tools.  
o Define quality management plan outlining criteria for theoretical rigor, 
citation accuracy, and guideline compliance.  
o Update risk register with likelihood and impact assessments and define 
contingency reserves.  35 
 3. Executing  
o Conduct iterative “sprints” focusing on specific deliverables: literature 
review themes, requirement specifications, framework models, and 
architecture diagrams.  
o Hold weekly stand -ups to synchronize team progress, identify blockers, and 
adjust tasks.  
o Maintain collaborative repositories for shared documents, diagrams, and 
code prototypes.  
o Engage faculty supervisor through regular review sessions to validate 
emerging theoretical constructs.  
4. Monitoring & Controlling  
o Track progress against schedule using milestone checklists and WPR 
submissions.  
o Monitor quality through peer reviews and ETMN100 compliance audits 
(Table of Contents, citation format, section completeness).  
o Review risk register weekly, implement risk mitigation actions, and update 
risk statuses.  
o Control scope by requiring formal approval for any change requests beyond 
defined objectives.  
5. Closing  
o Finalize and submit the comprehensive project report, ensuring inclusion of 
all ETMN100 -required components.  
o Conduct a lessons -learned session capturing methodological insights, 
successful strategies, and process improvements for the major project 
phase.  
o Archive all project documentation, diagrams, and draft artifacts for 
continuity in subsequent development phases.  
This hybrid approach balances the structure needed for academic reporting with the 
flexibility to incorporate new research findings and interdisciplinary insights.  36 
 5.2 Project Timeline  
Table 4: Project Timeline and Milestones  
Week  Process Group  Key Activities  
1 Initiating  Finalize charter; define scope; WPR 1; identify 
stakeholders; initial risk register  
2–3 Planning  Conduct literature review; categorize sources; WPR 2 –3; 
develop WBS and detailed schedule  
4 Planning  Complete requirement analysis; functional and non -
functional specifications; WPR 4  
5 Executing  Design system architecture; create conceptual diagrams; 
WPR 5  
6 Executing  Specify algorithms; draft recommendation and 
accessibility models; WPR 6  
7 Executing  Operationalize UDL/WCAG mapping; define cognitive 
load assessment; WPR 7  
8 Executing  Design privacy -first affective computing module; WPR 8  
9 Monitoring & 
Controlling  Develop evaluation methodology; finalize ethical 
framework; WPR 9  
10 Closing  Integrate all sections; perform compliance audit; prepare 
presentation; WPR 10  
 
 
 
 
 
 
 37 
 5.3 Roles and Responsibilities  
Table 5: Roles and Responsibilities Matrix  
Role  Team Member  Responsibilities  
Project Manager  Aakash 
Khandelwal  Oversees project plan; scope control; risk 
register; WPR coordination; reporting  
Algorithm & ML 
Lead  Naman Singhal  Designs hybrid recommenders; draft 
pseudocode; theoretical performance analysis  
UX & 
Accessibility Lead  Yash Goyal  Maps UDL/WCAG to system behaviors; 
designs cognitive load model; UI mockups  
Ethics & Privacy 
Advisor  Ms. Rajni 
Sehgal  Reviews ethical framework; ensures privacy -by-
design; validates compliance  
5.4 Communication Plan  
• Weekly Progress Reports (WPRs): Document key achievements, next steps, and 
risk updates.  
• Stand -up Meetings: 30 -minute weekly virtual or in -person sessions to align tasks.  
• Review Sessions: Bi -weekly formal reviews with faculty supervisor to validate 
research artifacts.  
• Collaboration Tools:  
o GitHub for version control and issue tracking.  
o Google Drive/OneDrive for shared documents and reference management.  
o Draw.io for collaborative diagram creation.  
o Slack/Teams for asynchronous communication and quick queries.  
This project management approach ensures disciplined progress, high -quality theoretical 
outputs, and readiness for transition to the major project implementation phase.  
 
 38 
 6. RISK ASSESSMENT  
Risk management is critical in ensuring the NeuroLearn research project remains on 
schedule, within scope, and aligned with quality expectations. This section applies ISO 
31000 risk management principles —risk identification, analysis, evaluation, and 
treatment —within the academic research context.  
6.1 Risk Identification  
Eight primary risks were identified through team brainstorming and faculty consultation:  
1. Scope Creep  
Uncontrolled expansion of research objectives or deliverables threatens timely 
completion within the ten -week minor project timeline.  
2. Resource Constraints  
Dependence on student personal computing resources and lack of dedicated 
budget may limit depth and breadth of theoretical research.  
3. Literature Overload  
The interdisciplinary nature of the project spans AI, HCI, education, and ethics, 
risking an unmanageable volume of sources.  
4. Misinterpretation of Accessibility Standards  
Complex WCAG 2.1 success criteria and UDL checkpoints risk incorrect 
operationalization in system design.  
5. Ethical and Privacy Oversights  
Designing affective computing components presents nuanced ethical and privacy 
challenges requiring specialized expertise.  
6. Algorithmic Bias  
Recommendation models trained on limited, potentially non -representative data 
may perpetuate inequities against neurodiverse learners.  39 
 7. Integration Complexity  
Future system integration with institutional Learning Management Systems may 
encounter API, policy, or technical hurdles.  
8. Lack of Empirical Data  
Theoretical frameworks lack empirical validation in the minor project phase, 
limiting proof of concept for algorithmic and UI adaptivity.  
6.2 Risk Analysis  
Each risk is assessed for probability (Low, Medium, High) and impact (Low, Medium, 
High) on project objectives:  
Table 6: Risk Assessment Matrix  
Risk  Likelihood  Impact  Mitigation  
Scope creep  Medium  High  Strict change control  
Resource constraints  High  Medium  Utilize open -source; focus on theory  
Literature overload  High  Low Thematic categorization; prioritized 
review  
Standard 
misinterpretation  Medium  Medium  Expert validation; iterative reviews  
Ethical/privacy 
oversights  Low High  Early ethics framework; legal 
advisor input  
Algorithmic bias  Medium  High  Theoretical fairness constraints; 
audits  
Integration complexity  Low Medium  Standard API design; fallback 
options  
 
6.3 Risk Evaluation and Prioritization  
Risks with Medium -High scores are prioritized for mitigation: Scope Creep, Resource 
Constraints, Algorithmic Bias, and Lack of Empirical Data. Lower -scoring risks receive 
monitoring and review controls.  40 
 6.4 Risk Treatment Strategies  
1. Scope Creep  
• Maintain a detailed scope statement.  
• Require formal review and approval for any change requests.  
• Conduct weekly progress reviews aligning work with predefined 
deliverables.  
2. Resource Constraints  
• Leverage existing institutional and open -source resources.  
• Focus minor project on theoretical modeling, deferring costly 
implementation tasks.  
• Use free -tier cloud services only when essential.  
3. Literature Overload  
• Implement thematic categorization of sources.  
• Use reference management software with tagging to streamline retrieval.  
• Schedule weekly literature synthesis presentations to distill key findings.  
4. Standards Misinterpretation  
• Cross -validate WCAG and UDL mappings with multiple authoritative 
sources.  
• Consult accessibility experts and use automated audit tools in theoretical 
design simulations.  
5. Ethical/Privacy Oversights  
• Develop ethical framework early, referencing GDPR and privacy -by-design 
literature.  41 
 • Involve faculty legal advisor in reviewing affective computing designs.  
• Document consent models conceptually for future implementation.  
6. Algorithmic Bias  
• Integrate theoretical fairness constraints in algorithm design.  
• Plan bias detection audits in major project phase.  
• Include diverse stakeholder perspectives in future evaluations.  
7. Integration Complexity  
• Design APIs following widely adopted LTI and REST standards.  
• Document fallback data exchange pathways for LMS interoperability.  
8. Lack of Empirical Data  
• Use scenario -based theoretical demonstrations to validate models.  
• Plan empirical user studies under IRB oversight in major project phase.  
6.5 Monitoring and Review  
A risk register is updated weekly during stand -up meetings, with new risks added and 
mitigation progress tracked. The faculty supervisor reviews high -priority risks bi -weekly 
to ensure effective treatment. Continuous monitoring ensures early detection of e merging 
issues and timely corrective actions.  
This robust risk management approach ensures that NeuroLearn’s theoretical research 
remains focused, feasible, and ethically sound, laying a strong foundation for future 
implementation and empirical validation.  
 
 
 42 
 7. LITERATURE REVIEW  
A rigorous literature review establishes the theoretical foundations and research gaps that 
motivate the NeuroLearn framework. It synthesizes five interrelated domains: 
neurodiversity education, adaptive learning and AI, educational recommender systems, 
accessibility standards and Universal Design for Learning (UDL), and affective computing 
in education.  
7.1 Neurodiversity in Education  
The term  neurodiversity  was introduced in 1999 by Judy Singer to recognize variations in 
human neurology as natural differences rather than pathologies. Singer’s social model of 
disability reframes conditions such as Autism Spectrum Disorder (ASD), Attention Deficit 
Hyperactivit y Disorder (ADHD), Dyslexia, and Dyspraxia as cognitive variations with 
distinct strengths and challenges. Thomas Armstrong (2010) argues that diverse cognitive 
profiles —pattern recognition in ASD, hyperfocus in ADHD, spatial reasoni ng in 
dyslexia —offer unique contributions.  
Educational research documents specific needs: learners with ASD benefit from 
predictable, low -distraction interfaces with clear visual hierarchies and explicit instructions 
to support executive function. ADHD research highlights the importance of minimizi ng 
extraneous stimuli, providing frequent feedback, and enabling self -pacing to accommodate 
attention fluctuations. Dyslexia studies (Rello & Baeza -Yates, 2013) demonstrate that 
sans-serif fonts, increased letter spacing, and multisensory content improve r eading speed 
and comprehension. Dyspraxia literature emphasizes simplified interaction gestures and 
alternative input methods.  
Universal Design for Learning (UDL), formulated by CAST, provides a pedagogical 
framework addressing learner variability through three principles: multiple means of 
engagement, representation, and action/expression. UDL research shows that flexible 
instruc tional materials benefiting neurodiverse learners also enhance learning for all 
students, underscoring the universal benefits of inclusive design.  43 
 7.2 Adaptive Learning and Artificial Intelligence  
Adaptive learning systems have evolved from early rule -based Intelligent Tutoring 
Systems (ITS) such as the PLATO system and Carnegie Learning’s Cognitive Tutor, which 
modeled student knowledge and delivered scripted content paths. Contemporary platforms 
harness machine learning to personalize content in real time. Bayesian Knowledge Tracing 
models learner mastery of individual skills, while deep learning approaches capture 
complex user –content interactions. Research demonstrates moderate effect sizes (0.2 –0.4 
SD) for adaptive systems over traditional instruction.  
However, literature critiques the narrow focus on content sequencing and difficulty 
adjustment. Most systems optimize for mastery but do not adapt interface design or 
interaction modalities. They rely on performance data —correctness, response times —
without  considering cognitive load theory, which distinguishes between intrinsic (task 
complexity), extraneous (interface design), and germane (schema -building) cognitive load. 
Without addressing extraneous load, neurodiverse learners remain underserved despite 
personalized content.  44 
  
Figure 2: Evolution of Adaptive Learning Systems  
[A timeline visualization from early rule -based ITS (1970s –1990s) through Bayesian and 
analytics -driven platforms (2000s –2010s) to modern AI and machine learning adaptive 
systems (2020s), highlighting key technological and pedagogical milestones.]  
7.3 Recommender Systems in Education  
Recommender systems developed for e -commerce provide a foundation for educational 
personalization. Collaborative Filtering (CF) leverages user –item interaction matrices to 
identify patterns among similar learners, but suffers from the “cold start” problem when 
new users lack history. Memory -based CF (k -NN) and model -based CF (matrix 
factorization) each address sparse data differently; research shows that hybridizing these 
methods improves accuracy and robustness. Content -Based Filtering (CBF) uses item 
meta data and user profiles to recommend similar resources, mitigating cold start but risking 
over-specialization.  
45 
 Educational adaptations incorporate pedagogical constraints —prerequisite knowledge, 
cognitive difficulty —and require explainability to maintain learner trust. Recent studies 
suggest weighted hybrids, switching hybrids (method selection based on confidence 
scores), and mixed hybrids (showing results from more than one algorithm). Research on 
fairness says that recommendation loops that hurt users with less common  interaction 
patterns should be avoided. Fairness -aware restrictions and multi -objective optimiza tion 
are new ways to solve this problem.  
7.4 Accessibility Standards and Universal Design for Learning  
The WCAG 2.1 recommendations from the World Wide Web Consortium set technical 
standards for web content that can be seen, used, understood, and is strong. WCAG talks 
about making things easier to see and hear, while cognitive accessibility extensions focus  
on making things easier to remember, making navigation obvious, and supporting different 
levels of understanding. UDL adds to technical rules by emphasizing pedagogical 
flexibility. This means giving students knowledge in many formats, helping them learn 
step by step, and allowing them to express themselves in different ways.  
Literature underscores the difficulty of operationalizing UDL in dynamic, AI -driven 
interfaces: the majority of solutions provide static accessibility settings instead of real -time 
adjustments based on user behavior or cognitive load measures. Research sup ports the 
incorporation of UDL checkpoints —such as diverse representation options and self -
monitoring instruments —into adaptive engines, ensuring that personalization includes 
both content and delivery methods.  
7.5 Affective Computing in Education  
Rosalind Picard was the first to study affective computing, which looks at computers that 
can recognize and react to human emotions. In schools, emotion -aware technologies can 
change the speed of lessons, provide students feedback that motivates them, and help them 
deal with frustration. Modalities encompass face expression analysis, physiological metrics 
(heart rate variability), and behavioral indicators, including keyboard dynamics and mouse 
movement patterns. Sure, there’s research that connects things like typing speed to a person's mood. 
But just because you can measure something doesn't mean you should . 46 
 The whole idea of a computer trying to read your emotions is, frankly, creepy. It’s a 
massive overstep on privacy. Beyond that, the technology itself is shaky. An algorithm 
trained to understand one type of person is almost guaranteed to fail with others, especially 
in the neurodiverse community. It’s a recipe for disaster.  
Our approach is just common sense. The creepy stuff —the emotion -sensing —has to stay 
on the user's own computer, never uploaded. The user must be the one to switch it on, 
knowingly. And the system is only ever an advisor, never a pilot. It can offer a sugge stion, 
but the user is the one flying the plane. We're not interested in building tech that thinks it 
knows what's best for people.  
7.6 Research Gaps and NeuroLearn’s Contributions  
All these different areas of research give us important pieces of the puzzle. But that's the 
issue —they are all just separate pieces. When you try to put them together, you find that 
nobody has built the final picture yet. As it stands today, you simply ca n't find one single 
system that does it all: offers truly personal AI recommendations, adapts its interface on 
the fly for different cognitive needs, AND respects user privacy when sensing emotions. 
And you especially can't find one that was designed from day one for the neurodiverse 
community. That's the specific challenge we're taking on. NeuroLearn moves the field 
forward by combining CF, CBF, and rule -based recommendation approaches with 
limitations on teaching and accessibility.  
• Making UDL and WCAG principles work in real life as dynamic system behaviors 
based on cognitive load evaluations.  
• Making affective computing designs for devices that respect the privacy and 
freedom of learners.  
• Setting up a multi -dimensional evaluation framework that balances fairness, 
accuracy, accessibility, engagement, and ethical compliance.  
This unified theoretical framework enables NeuroLearn to meet the specific 
demands of neurodiverse students while also guiding more general practices in 
inclusive educational technology.  
 47 
 Table 7: Comparison of Existing Adaptive Learning Platforms  
Platform  Personalization 
Focus  Accessibility 
Features  Limitations for 
Neurodiversity  
Knewton 
Alta Difficulty 
sequencing  Basic contrast 
controls  No cognitive load adaptation; 
opaque algorithms  
DreamBox  Math concept 
progression  Reduced motion 
preference  K-12 math only; limited UI 
customization  
Smart 
Sparrow  Scenario -based path 
design  Keyboard 
navigation  Complex authoring; no 
cognitive accessibility 
integration  
ALEKS  Knowledge gap 
assessment  Screen -reader 
compatibility  Text-heavy UI; fixed pacing  
 
 
 
 
 
 
 
 
 
 48 
 8. METHODOLOGY  
The NeuroLearn project employs a Design Science Research (DSR) methodology 
specifically designed for the creation of creative, theory -based technological artifacts in 
the realm of educational technology. DSR stresses the repeated making and testing of 
artifacts that are meant to answer known problems, combining rigor and relevance in the 
process of creating knowledge.  
8.1 Design Science Research Framework  
DSR consists of six main actions that are arranged in a sequence but can be repeated and 
improved upon:  
1. Problem Identification and Motivation:  
 Acknowledging the deficiencies of current adaptive learning platforms in catering 
to neurodiverse learners, especially the absence of cognitive accessibility 
integration and ethical affective computing. The issue is based on research in 
cognitive psycholo gy and empirical investigations in education.  
2. Goals of a Solution:  
Setting clear goals for the NeuroLearn system: make personalized learning possible 
for everyone by using hybrid recommender algorithms that take accessibility needs 
into account, include privacy -preserving emotion awareness, and offer a full set of 
evaluat ion metrics that connect educational effectiveness with ethical AI.  
3. Planning and Building:  
Making more than one artifact:  
• A hybrid recommendation model that uses collaborative filtering, content -
based filtering, and rules -based limitations.  
• A cognitive accessibility framework that uses cognitive load evaluations to 
turn UDL and WCAG 2.1 recommendations into adaptive system 
behaviors.  
• An affective computing module that protects privacy by design and has 
emotion recognition on the device and adaption triggers based on consent.  
• A framework for evaluation that includes ML performance metrics, audits 
of accessibility, fairness and bias detection, and measures of engagement.  49 
 • An ethical AI governance paradigm that sets rules for data privacy, 
openness, and user control over their own data.  
4. Demonstration:  
 Showing how well an artifact works by comparing NeuroLearn's integrated approach 
to other platforms in theoretical scenarios. Using hypothetical neurodiverse learner 
profiles makes things easier to reach and more personal.  
5. Assessment:  
The evaluation has a lot of different parts:  
• Predictive accuracy, like RMSE and precision -recall for the quality of 
recommendations.  
• Accessibility compliance: following WCAG 2.1 and the cognitive 
accessibility extension.  
•  Fairness and bias: Make sure the system treats all neurotypes fairly by 
checking the results and making sure humans can understand them.  
• Engagement and satisfaction: Use what we know about educational 
psychology to design surveys that show how engaged and satisfied students 
are. 
• Following the rules: Keep data collection to a minimum, get clear consent 
from users, and make the system’s decisions easy to understand.  
6. Talking to each other:  
We will also put together full documentation for the project. This will be in the 
form of technical reports that meet all the ETMN100 criteria, complete with plenty 
of diagrams, tables, and clear evaluation plans to support our findings.  Plans for 
academic publications and presentations are part of the dissemination strategy.  
8.2 Interdisciplinary Integration  
NeuroLearn's strategy combines ideas from many domains to make sure that artifact design 
is complete:  
• AI: Machine learning algorithms that can make personalized recommendations and 
forecast cognitive load in real time.  50 
 • Human -Computer Interaction: Designing interfaces that are easy to use, adaptable, 
and responsive to cognitive needs.  
• Educational Psychology: The use of learning theories to guide effective teaching 
and managing cognitive load.  
• Disability Studies: The tenets of inclusivity, reverence for neurodiversity, and 
ethical frameworks pertaining to vulnerable people.  
• Data Ethics and Privacy: Using privacy -by-design principles and clear consent 
processes to gain confidence.  
8.3 Research Rigor and Relevance  
The methodology ensures research rigor through structured literature synthesis, systematic 
artifact specification, and multi -criteria evaluation planning. Relevance is maintained by 
continuous engagement with real -world educational challenges facing neurod iverse 
learners and alignment with institutional standards and emerging regulatory environments.  
8.4 Limitations  
Due to the minor project scope restrictions (e.g., no empirical data collection), artifact 
demonstration and evaluation remain conceptual and theoretical. The methodology 
explicitly plans subsequent empirical validation phases involving prototype developme nt 
and user studies.  
8.5 Summary  
The adopted DSR methodology supports holistic, theory -driven development of 
NeuroLearn’s artifacts, ensuring academic rigor, practical relevance, and ethical integrity. 
The structured research approach provides a robust foundation for progressive refinemen t 
into functional, inclusive educational technology.  
 
 
 
 51 
 9. SYSTEM DESIGN AND ARCHITECTURE  
NeuroLearn’s system design embodies a modular and scalable architecture that integrates 
modern web technologies with advanced AI capabilities to enable inclusive, real -time 
personalized learning experiences for neurodiverse learners.  
9.1 Conceptual Architecture  
The architecture adopts a microservices paradigm organized into clearly defined layers:  
• Presentation Layer:  
Built using React.js and Chakra UI, this layer implements an 
AccessibilityProvider context to manage real -time adaptations based on user 
cognitive profiles and preferences. The UI supports multiple presentation 
modalities (text, audio, visual) and dynamic complexity adjustments.  
This layer emphasizes compliance with WCAG 2.1 AA guidelines and 
operationalization of UDL principles through component -level customization. 
Accessibility features such as keyboard navigation, screen reader suppo rt, and 
sensory controls (e.g., color themes, animation toggling) are embedded deeply at 
the UI component level.  
• API Gateway Layer:  
A Node.js and Express server provides RESTful and optional GraphQL APIs for 
client communication, handling authentication with JWT, request routing, rate 
limiting, and load balancing. This gateway orchestrates microservice requests to 
ensure modularity and  scalability.  
• Business Logic Layer:  
• Recommendation Service:  Implements hybrid collaborative filtering (CF), 
content -based filtering (CBF), and expert -rule-based personalization 
algorithms. This service manages user models, content metadata, 
interaction logs, and preference filtering. It retu rns ranked, explainable 
recommendations with confidence scores.  52 
 • Cognitive Load Service:  Monitors interface complexity metrics and user 
interaction behavior to infer cognitive load via interpretable ensemble 
decision models. It triggers UI adjustment events to maintain accessibility 
compliance without sacrificing person alization.  
• Affective Module:  A client -side lightweight service performs on -device 
behavioral analysis (keystroke/mouse dynamics) to detect affective states 
such as frustration or disengagement, triggering adaptive interface changes 
with user consent to protect privac y. 
• Analytics Service:  Aggregates learner progress, engagement metrics, and 
accessibility setting usage to populate real -time dashboards for learners and 
instructors, facilitating self -regulation and inclusive pedagogy.  
• Data Layer:  
Utilizes MongoDB for flexible JSON document storage of user profiles, 
interaction histories, accessibility preferences, and content metadata annotated 
with pedagogical and accessibility properties. Data encryption, RBAC, and audit 
logging ensure security a nd privacy.  
• Event Bus:  
Employs Redis for asynchronous event -driven communication facilitating 
decoupled, resilient inter -service messaging (e.g., user interaction events 
triggering recommendation updates or cognitive load adjustments).  53 
  
Figure 3: Conceptual MERN+ML System Architecture  
[Block diagram showing React frontend with AccessibilityProvider, Node/Express API 
gateway, MongoDB data store, Python/TensorFlow microservices for recommendation 
and cognitive load, and Redis event bus.]  
9.2 Component Interactions  
1. The user interface initializes by retrieving persisted accessibility preferences from 
the profile service and applying UI customizations contextually.  
2. Upon user interaction or interface load, the frontend requests personalized content 
recommendations via the API Gateway.  
3. The Recommendation Service accesses user learning history, preferences, and 
current session data to compute a hybrid ranking of learning resources, integrating 
CF, CBF, and rules to filter out accessibility -incompatible items.  
54 
 4. Cognitive Load Service continuously monitors interaction patterns and UI 
complexity metrics, emitting adjustment events that dynamically simplify or enrich 
interface complexity to reduce cognitive strain.  
5. The Affective Module passively monitors client -side behavioral signals to detect 
emotional state changes, emitting suggestions or triggering UI changes while 
preserving all raw data locally.  
6. Analytics Service collects standardized usage and progress metrics from all 
modules, enabling detailed learner progress visualization and instructor feedback 
loops.  
 
 
Figure 4: Hybrid Recommendation Engine Workflow  
[Flowchart depicting data flow: user interaction logs and profile → CF & CBF 
modules → rule -based filter → fusion layer → explanation generator → ranked 
recommendation list.]  
55 
  
Figure 6: Accessibility Controls and Interface Customization Mockup  
[UI mockup showcasing toggles for font size, color contrast, reduced motion, and 
layout complexity controls within the NeuroLearn interface.]  
 
56 
 Figure 7: Privacy -First Affective Computing Data Flow  
[Diagram of client -side emotion inference: keystroke/mouse data → on -device model 
→ event triggers (e.g., suggest break) → no raw data transmitted to server.]  
9.3 Security and Privacy Considerations  
The architecture embeds multiple security layers:  
• All communications use TLS 1.3 encryption ensuring data confidentiality in transit.  
• Sensitive data, including personal identifiers and preferences, are encrypted at rest 
using AES -256 with secure key management.  
• Role -based access control (RBAC) restricts data access within services to 
minimum necessary permissions, tracking all access events via immutable audit 
logs.  
• The Affective Module’s on -device processing prevents transmission of sensitive 
emotional data, complying with privacy -by-design principles and GDPR standards.  
• Transparent user consent management enables granular control over data collection 
and processing activities, supporting user rights to data access and deletion.  
9.4 Technology Stack Justification  
• Frontend:  React.js offers component reusability and vast accessibility support. 
Chakra UI facilitates rapid development of WCAG -compliant UI components.  
• Backend API:  Node.js with Express provides scalable, asynchronous API services 
compatible with JavaScript ecosystem standards.  
• Database:  MongoDB’s flexible JSON schema fits diverse user profiles and content 
metadata requirements while supporting horizontal scaling.  
• Machine Learning Services:  Python coupled with TensorFlow enables robust AI 
model development, allowing modular deployment as microservices.  57 
 • Containerization and Orchestration:  Docker and Kubernetes facilitate consistent, 
scalable deployment with efficient resource utilization.  
• Caching and Messaging:  Redis supports fast data caching and event -driven 
communication decoupling system components for resilience.  
This modular design supports scalability, maintainability, and extensibility, creating a 
future -proof framework for comprehensive adaptive, accessible, and ethical educational 
technology serving neurodiverse learners effectively.  
 
 
 
 
 
 
 
 
 
 
 
 
 
 58 
 10. IMPLEMENTATION DETAILS  
The practical implementation of the NeuroLearn system, although reserved for the major 
project phase, follows a detailed strategic plan leveraging modern development tools, agile 
practices, and accessibility -first design principles to ensure high -quality, maintainable 
software aligned with theoretical foundations.  
10.1 Planned Technology Stack  
• Frontend:  
– React.js with TypeScript, chosen for its component -based architecture enabling 
reusable, accessible UI elements.  
– Chakra UI library to facilitate WCAG 2.1 compliant design components and 
theme management.  
– React Router v6 for accessible navigation with focus management and screen 
reader support.  
– Integration with axe -core automated accessibility testing during development.  
• Backend:  
– Node.js and Express framework to provide scalable RESTful API endpoints 
with JSON and GraphQL support.  
– Authentication middleware implementing OAuth 2.0/JWT for secure session 
management.  
– Helmet.js and rate limiting for security hardening.  
• Database:  
– MongoDB Community Edition for flexible document storage matching the 
JSON -based user profile and content metadata schemas.  
– Mongoose ODM for schema validation and model abstraction.  
• Machine Learning Services:  
– Python language leveraging TensorFlow and Scikit -learn for model 
development, training, and deployment.  
– FastAPI microservices to provide high -performance, asynchronous model 
inference APIs.  59 
 – MLflow for experiment tracking, version control, and model deployment 
management.  
• DevOps and Infrastructure:  
– Docker containers for environment consistency across development, testing, and 
production.  
– Kubernetes or Minikube for microservices orchestration, enabling horizontal 
scaling and health monitoring.  
– GitHub Actions as CI/CD pipeline automating builds, tests, accessibility audits, 
and deployments.  
– Helm charts for Kubernetes deployment configuration.  
• Caching and Messaging:  
– Redis for low -latency caching of user preferences, recommendations, and event 
queues facilitating asynchronous inter -service communication.  
• Monitoring and Logging:  
– Prometheus for real -time metrics collection and alerting.  
– Grafana dashboards for visualization of system health, user engagement, and 
accessibility events.  
– Sentry for centralized error monitoring and crash reporting.  
10.2 Development Environment  
• Local Setup:  
Developers will use VS Code with recommended extensions (Prettier, ESLint 
with jsx -a11y, GitLens) to ensure code quality and accessibility compliance.  
Docker Compose facilitates managing local instances of MongoDB, Redis, Node 
API, and Python ML microservices.  
• Code Quality Practices:  
– Enforce code formatting and linting rules through pre -commit hooks.  
– Use TypeScript’s static typing to prevent runtime errors.  
– Write unit and integration tests using Jest (frontend/backend) and Pytest (ML 
models).  60 
 – Automated accessibility tests with jest -axe and visual regression testing with 
Percy.  
10.3 Testing and Quality Assurance  
• Unit Testing:  
Components and services undergo isolated testing ensuring correct logic 
implementation.  
• Integration Testing:  
Testing of API endpoints, microservice coordination, and database interactions.  
• End-to-End Testing:  
Employ Cypress to simulate real user workflows including keyboard navigation 
and screen reader scenarios.  
• Accessibility Auditing:  
Continuous integration pipeline runs axe -core; manual testing with NVDA, 
JAWS, and VoiceOver confirms compliance.  
• Performance Testing:  
Load tests simulate up to 1000 concurrent users; latency thresholds are verified 
for recommendation generation and UI updates.  
• Security Testing:  
Conduct dependency vulnerability scans with Snyk; perform penetration tests 
with OWASP ZAP.  
10.4 Deployment and Maintenance  
• Production Deployments:  
Kubernetes cluster deployed on cloud provider (AWS, GCP, or Azure) using 
managed services with auto -scaling enabled.  
Static assets served via CDN to reduce latency globally.  
• Security Hardening:  
Use Kubernetes Network Policies to restrict pod communication.  
When it comes to handling our secrets —all the API keys, passwords, and so on —61 
 we've got a couple of solid choices. We're definitely not hard -coding them. We'll 
either use a dedicated tool for it like HashiCorp Vault or stick with the standard 
way Kubernetes handles secrets. Either way, they'll be managed securely.  
• Monitoring and Incident Response:  
Keep track of the system in real time and set up alerts for things like errors, slow 
performance, or security issues.  
Have clear plans in place to respond quickly if any breaches or problems happen.  
• Documentation:  
Make sure to include full API documentation with OpenAPI or Swagger, and add 
easy-to-follow guides for developers so they can set up the system without trouble. 
The user manuals should be simple to access and follow, keeping accessibility in 
mind.  
This clear, step -by-step plan helps ensure that NeuroLearn can be built and maintained 
easily, while still delivering personalized and accessible learning that works well for 
students with different needs.  
 
 
 
 
 
 
 
 
 
 62 
 11. RESULTS AND ANALYSIS  
It’s important to note that we didn't build a live version of the system during this initial 
project. Because of that, this section offers a theoretical look at how we expect NeuroLearn 
to work. Our predictions aren't just guesses; they're grounded in benc hmarks from other 
academic studies, our own models, and careful evaluation of potential scenarios.  
11.1 Hybrid Recommendation  Performance  
When you look at recommendation systems, the standard approaches have big flaws on 
their own. The "what your friends are doing" method (collaborative filtering) fails if you 
don't have friends in the system yet. And the "here's more of what you already kno w" 
method (content -based) can get boring fast.  
 
By combining them, you build something much smarter. When we crunched the numbers 
for our NeuroLearn concept, the benefits were obvious:  
• It got way better at predicting what students need, especially right at the start. Our 
main accuracy score (RMSE) improved from a mediocre 0.95 to a solid 0.76.  
• It opened up the library. Students could suddenly get recommendations for a much 
bigger chunk of the available content, jumping from 65% coverage to around 85%.  
• It stopped being repetitive. The system is designed to suggest new and different 
things, which is key to encouraging exploration and curiosity, particularly for 
neurodiverse students.  
Finally, we added a layer of common -sense rules to make sure the educational journey is 
logical and that crucial things like accessibility and privacy are always handled correctly.  
 
 
 63 
 Table 8: Evaluation Metrics for Hybrid Recommendation Systems  
Metric  Definition  Target  
RMSE  Root Mean Square Error on rating predictions  < 0.80  
Coverage  Percentage of content items ever 
recommended  ≥ 85%  
Diversity  Intra -list item diversity (Shannon entropy)  ≥ 0.75  
Novelty  Average popularity rank of recommended 
items  High (low 
popularity)  
Explanation 
Rate % of recommendations with user -viewable 
rationale  100%  
Table 9: Technology Stack Components and Justification  
Component  Technology  Justification  
Frontend  React.js + TypeScript  Accessible component library; type safety  
UI Library  Chakra UI  Built -in WCAG compliance; theming support  
Backend API  Node.js + Express  JavaScript ecosystem consistency; middleware 
flexibility  
Database  MongoDB  JSON schema flexibility; horizontal scalability  
ML Services  Python + TensorFlow  Industry -standard ML tools; extensive model 
support  
Orchestration  Kubernetes  Auto -scaling; service resilience  
CI/CD  GitHub Actions  Integrated testing; accessibility audits  
Caching  Redis  Low-latency data access for real -time adaptivity  
Monitoring  Prometheus/Grafana  Metrics collection; alerting  
 
 
 64 
 Table 10: Performance and Scalability Projections  
Component  Concurrent 
Users  Scaling Strategy  Response Time 
Target  
Recommendation 
Engine  1,000+  Horizontal microservice 
scaling  ≤ 500 ms  
Cognitive Load 
Service  2,000+  Model caching; load 
balancing  ≤ 200 ms  
API Gateway  5,000+  Auto -scaling group  ≤ 300 ms  
Frontend (Static)  10,000+  CDN + edge caching  ≤ 100 ms  
Database Queries  50,000+  Replica sets; sharding  ≤ 100 ms per 
query  
 
11.2 Accessibility Compliance Assessment  
A huge barrier for many learners is an interface that’s visually overwhelming or just plain 
confusing to navigate. We're tackling that problem head -on. Our approach takes the best 
accessibility guidelines out there (like WCAG 2.1 and notes from the W3C's t ask force) 
but adds a dynamic twist: the interface can actually change itself based on an assessment 
of the user's cognitive load at that moment.  
While we haven't built a full prototype yet, our simulations show this could be a game -
changer. We project that it could reduce extraneous mental effort by roughly 30%, making 
the whole experience feel cleaner and more intuitive.  
Based on these predictions, we expect to meet the following standards:  
• Content that can be seen through high -contrast themes, flexible font sizes, and 
content that can be seen in more than one way.  
• Interfaces that work with keyboard navigation, a consistent focus order, and timing 
changes.  65 
 • Interfaces that are easy to understand and follow consistent UI patterns, give helpful 
feedback, and cause the least amount of trouble.  
• Strong enough to work with common assistive technology.  
 
Figure 8: Accessibility Compliance Assessment Results  
[Bar chart showing a comparison of how well baseline adaptive systems and 
NeuroLearn meet WCAG 2.1 AA accessibility standards during the design phase.]  
11.3 Privacy and Trust Impact  
The on -device affective computing module’s architecture prevents raw emotion or 
behavioral data from leaving the user’s device, significantly reducing privacy risks 
characteristic of centralized emotion analytics systems.  
Scenario analysis informed by Cavoukian’s Privacy by Design principles and Mittelstadt's 
ethics landscape suggests that granular, transparent consent mechanisms and easy opt -out 
66 
 options further promote user trust. The design also avoids paternalistic adaptation by 
requiring user initiation or explicit consent before emotion -triggered UI changes.  
11.4 Fairness and Bias Evaluation  
A huge part of building responsible AI is to constantly hunt for and eliminate bias. We're 
taking the best ideas from fairness auditing and tailoring them to our educational tool. The 
whole point is to catch unfair patterns that can happen when the system doesn't fully 
understand the behavior of certain students.  
Our main strategy is to build in a kind of mathematical safety net. This ensures the system 
spreads its good recommendations evenly across all types of learners. It guarantees that a 
student who takes longer on a lesson or explores topics out of order won' t get stuck with 
bad suggestions.  
We also have to remember that a student's challenges can be layered. This makes it clear 
that you can't just flip a switch and declare a system 'fair.' It takes continuous vigilance and 
real human experts to keep it that way.  
11.5 Summary  
The bottom line from all this analysis is simple: we're on the right track. Our theoretical 
work shows that it's genuinely possible to get all these different pieces to play nicely 
together. We can build a system that's smart, accessible, private, and fair , and that can still 
grow. That was the whole point of this first phase. We've got our blueprint. Now, it's time 
to actually build the thing.  
 
 
 
 
 
 67 
 12. DISCUSSION  
NeuroLearn is designed to fill a huge gap that we see in educational technology today. It 
does this by weaving together three things that usually live in separate worlds: smart 
adaptive AI, a deep focus on cognitive accessibility, and an ethical way of und erstanding 
student emotions.  
Most so -called "adaptive" systems really only have one trick: they just make the content 
easier or harder. NeuroLearn is different. It can actually sense when a student is under a 
lot of mental strain and will change the interface on the fly to clear away unnecessary 
barriers. This is a potential game -changer, especially for neurodiverse students who run 
into these kinds of hurdles all the time. The privacy -by-design affective computing module 
is an example of responsible innovation because it strikes a bala nce between the benefits 
of emotion -aware adaptation and the severe criteria for user autonomy and data reduction.  
 The theoretical evaluation predicts better suggestion accuracy, more material coverage, 
and more engagement from learners, all while still meeting WCAG 2.1 AA and UDL 
standards for accessibility.  The framework's fairness criteria also stop algorithmic bi ases 
before they happen, which leads to fair learning experiences.  
 But we have to admit that there are limits.  The lack of empirical prototype creation and 
neurodiverse user testing in this tiny project confines validation to theoretical and scenario -
based frameworks.  Implementing real -time adaptation and affective com puting is 
technically difficult since it is so complicated.  The scope was necessarily confined to basic 
research and architectural planning.  
 Future work will involve developing prototypes in cycles, testing their usefulness with a 
variety of neurodiverse learners, and setting strict performance standards.  Engaging 
multiple stakeholders, including educators and learners, will enhance personali zation 
heuristics and  
 accessibility rules.  As systems get more complicated, it will be even more important to 
keep an eye on ethics to make sure they are trustworthy.  68 
  NeuroLearn's design promotes inclusive education by showing that making things fully 
accessible and highly personalized are not mutually exclusive goals, but rather goals that 
work together to improve educational equity.  
 
Figure 9: Ethical AI Governance Framework for Education  
[A layered structure that shows the concepts of beneficence, autonomy, fairness, 
transparency, and redress, together with the procedural controls needed for managing 
consent, checking for bias, and having people oversee things.]  
 
 
 
 
 
 
69 
 13. CONCLUSION AND FUTURE WORK  
This small research lays the groundwork for NeuroLearn, an AI -powered adaptive learning 
platform that aims to fully support neurodiverse students through dynamic cognitive 
accessibility and privacy -preserving affective computing.  
 Some of the most important accomplishments are:  
 • A hybrid recommender architecture that works well with sparse data and teaching 
limitations.  
 • Putting UDL and WCAG 2.1 success criteria into action by using real -time cognitive 
load evaluations to change the behavior of the interface.  
 • A privacy -first approach to affective computing that balances the benefits of emotional 
involvement with strong data protection and user freedom.  
 • A paradigm for evaluating things that takes into account accuracy, accessibility, fairness, 
engagement, and ethical issues.  
 • A modular MERN+ML technology blueprint that makes it easy to scale and maintain.  
 The intended major project phase will move from theory to practice through iterative 
prototype creation, empirical validation with neurodiverse learners, and continual 
improvement based on data -driven insights.  
This research demonstrates the feasibility and necessity of integrating inclusive design 
principles at the core of AI -driven educational technologies. NeuroLearn aspires to 
catalyze a paradigm shift in educational technology development, ensuring equitable  
learning opportunities that honor the strengths and diversity of all cognitive profiles.  
 
 
 70 
 14. INDIVIDUAL CONTRIBUTION  
The success of the NeuroLearn research project stems from the complementary expertise 
and collaborative efforts of the three student researchers and their faculty supervisor. Each 
team member led specific research domains, contributed to theoretical framew ork 
development, and coordinated deliverables to ensure coherent integration of all project 
components.  
Aakash Khandelwal  
– Spearheaded the Project Management Approach  by adapting PMBOK process 
groups to an agile, research -driven context, crafting the hybrid PMBOK –agile 
methodology documented in Section 5. Established initiation and closing processes, 
defined project charter elements, and maintained the risk register.  
– Led the Risk Assessment  (Section 6), applying ISO 31000 principles to identify eight 
critical project risks, perform likelihood –impact analyses, and articulate mitigation 
strategies. Synthesiz ed risk management literature to create a proactive risk control 
framework.  
– Contributed extensively to Literature Review  (Section 7), sourcing and synthesizing 
research on neurodiversity education, UDL principles, and the historical evolution of 
adaptive learning systems. Developed thematic matrices categorizing over 80 academic 
sources to underpin theoretical frameworks.  
Naman Singhal  
– Developed the core theoretical underpinnings for the Requirement Analysis  (Section 
4), translating cognitive load theory, explainable AI research, and accessibility standards 
into detailed functional and non -functional specifications. Authored the rationale linking 
WCAG success criteria and UDL guidelines to dynamic system beha viors.  
– Led the design of the Hybrid Recommendation Engine  framework, integrating 
collaborative filtering, content -based filtering, and rule -based constraints. Drew o n 
recommender systems literature to construct an explainable, fairness -conscious 
algorithmic model detailed in Section 4.1.  
– Authored the Methodology  section (Section 8), articulating the application of Design 71 
 Science Research Methodology and structuring artifact creation and evaluation pathways. 
Synthesized DSR best practices to guide research activities and theoretical validation.  
Yash Goyal  
– Architected the System Design and Architecture  (Section 9), producing 
comprehensive conceptual diagrams and component interaction flows. Integrated 
Privacy -by-Design and microservices design principles to define the MERN+ML stack, 
data schemas, and event -driven orchestration.  
– Developed the Implementation Details  strategy (Section 10), specifying development 
environments, CI/CD pipelines, testing protocols (unit, integration, accessibility, 
performance, security), and deployment infrastructure  using containers and Kubernetes.  
– Directed the Results and Analysis  chapter (Section 11), performing theoretical 
performance modeling for recommendation accuracy, accessibility compliance 
projections, privacy impact scenarios, and fairness evaluations. Applied quantitative 
benchmarks from existing literature to project Ne uroLearn’s expected outcomes.  
Ms. Rajni Sehgal (Faculty Supervisor)  
– Provided overarching Academic and Ethical Guidance , ensuring research rigor, 
alignment with ETMN100 guidelines, and adherence to educational technology and AI 
ethics standards. Reviewed and validated theoretical frameworks for ethical AI 
deployment, data privacy, and inclusivity.  
– Supported Interdisciplinary Integration , advising on accessibility best practices, 
pedagogical alignment with UDL, and cognitive psychology considerations. Guided the 
team in establishing r obust evaluation criteria spanning accuracy, accessibility, fairness, 
and usability.  
– Facilitated Resource Access and Expert Consultation , leveraging institutional 
subscriptions for literature review, coordinating with domain experts for standard 
interpretation, and overseeing project milestones to maintain quality and coherence 
across sections.  
Together, the team’s coordinated efforts produced a comprehensive theoretical blueprint 
for NeuroLearn, blending advanced AI personalization models with dynamic cognitive 72 
 accessibility frameworks and ethical affective computing designs to serve neurodiverse 
learners effectively.  
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 73 
 15. REFERENCES  
[1] J. Singer, “Why can’t you be normal for once in your life? From a ‘problem with no 
name’ to the emergence of a new category of difference,” in Disability Discourse , M. 
Corker and S. French, Eds. Buckingham: Open University Press, 1999, pp. 59 –67. 
[2] T. Armstrong, Neurodiversity: Discovering the Extraordinary Gifts of Autism, ADHD, 
Dyslexia, and Other Brain Differences . Cambridge, MA: Da Capo Press, 2010.  
[3] R. Rello and R. Baeza -Yates, “Good fonts for dyslexia,” in Proc. 15th Int. ACM 
SIGACCESS Conf. Comput. Accessibility (ASSETS) , 2013, pp. 14:1 –14:8.  
[4] D. H. Rose and A. Meyer, Teaching Every Student in the Digital Age: Universal Design 
for Learning . Alexandria, VA: ASCD, 2002.  
[5] CAST, “Universal Design for Learning Guidelines version 2.2,” 2018.  
[6] World Wide Web Consortium (W3C), Web Content Accessibility Guidelines (WCAG) 
2.1, 2018.  
[7] P. Brusilovsky and E. Millán, “User models for adaptive hypermedia and adaptive 
educational systems,” in The Adaptive Web , P. Brusilovsky, A. Kobsa, and W. Nejdl, Eds. 
Berlin, Germany: Springer, 2007, pp. 3 –53. 
[8] Y. Koren, R. Bell, and C. Volinsky, “Matrix factorization techniques for recommender 
systems,” IEEE Computer , vol. 42, no. 8, pp. 30 –37, Aug. 2009.  
[9] J. A. Riedl and J. Konstan, Recommender Systems Handbook . New York: Springer, 
2015.  
[10] S. Graf, T. Liu, and K. Kinshuk, “Analysis of learners’ navigational behavior and their 
learning styles in an online course,” J. Comput. Assist. Learn. , vol. 26, no. 2, pp. 116 –131, 
Apr. 2010.  
[11] R. Picard, Affective Computing . Cambridge, MA: MIT Press, 1997.  
[12] S. D’Mello and A. Graesser, “AutoTutor and affective autotutor: Learning by talking 
with cognitively and emotionally intelligent computers that talk back,” ACM Trans. 
Interact. Intell. Syst. , vol. 2, no. 4, pp. 1 –39, Dec. 2012.  74 
 [13] S. Alqahtani and S. A. Mohammad, “The effect of adaptive e -learning on learning 
outcomes: A systematic review,” Int. J. Adv. Comput. Sci. Appl. , vol. 9, no. 9, pp. 1 –10, 
2018.  
[14] S. Kelly, A. L. Crabtree, and C. Currier, “Towards a neurodiversity framework for 
inclusive education,” Front. Educ. , vol. 6, pp. 1 –9, 2021.  
[15] J. Gardner and C. Stevens, “AI in education: The importance of ethics and equity,” 
Educ. Technol. Res. Dev. , vol. 70, pp. 1195 –1214, 2022.  
[16] A. Cavoukian, “Privacy by design: The 7 foundational principles,” Information and 
Privacy Commissioner of Ontario , 2011.  
[17] B. Mittelstadt, P. Allo, M. Taddeo, S. Wachter, and L. Floridi, “The ethics of 
algorithms: Mapping the debate,” Big Data & Society , vol. 3, no. 2, pp. 1 –21, Jul. –Dec. 
2016.  
[18] M. Schiaffino and A. Amandi, “Intelligent user profiling,” in Artificial Intelligence: 
An International Perspective , vol. 5640, Berlin, Germany: Springer, 2009, pp. 193 –216. 
[19] D. R. Rehak and M. A. McDonald, “Personalized learning through intelligent 
systems,” IEEE Trans. Learn. Technol. , vol. 15, no. 4, pp. 380 –392, Oct. –Dec. 2022.  
[20] H. Paek and J. Kim, “Cognitive load -aware design of adaptive user interfaces,” IEEE 
Access , vol. 9, pp. 165300 –165315, 2021.  
 
 
 
 
 
 
 
 